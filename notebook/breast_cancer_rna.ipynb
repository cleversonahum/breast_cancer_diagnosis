{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer detection with neural networks\n",
    "This notebook contains an example of classification, using neural networks aiming to detect the severity of breast cancer on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from pprint import pprint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "This breast cancer databases was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump</th>\n",
       "      <th>U_Cell_size</th>\n",
       "      <th>U_Cell_shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>SE_epitelial_cell_size</th>\n",
       "      <th>Bare_nuclei</th>\n",
       "      <th>bland_chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Clump  U_Cell_size  U_Cell_shape  Marginal_Adhesion  \\\n",
       "0  1000025      5            1             1                  1   \n",
       "1  1002945      5            4             4                  5   \n",
       "2  1015425      3            1             1                  1   \n",
       "3  1016277      6            8             8                  1   \n",
       "4  1017023      4            1             1                  3   \n",
       "\n",
       "   SE_epitelial_cell_size Bare_nuclei  bland_chromatin  Normal_Nucleoli  \\\n",
       "0                       2           1                3                1   \n",
       "1                       7          10                3                2   \n",
       "2                       2           2                3                1   \n",
       "3                       3           4                3                7   \n",
       "4                       2           1                3                1   \n",
       "\n",
       "   Mitoses  Class  \n",
       "0        1      2  \n",
       "1        1      2  \n",
       "2        1      2  \n",
       "3        1      2  \n",
       "4        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "data_csv = \"../breast-cancer-wisconsin.csv\"\n",
    "df = pd.read_csv(data_csv, names=['ID','Clump','U_Cell_size','U_Cell_shape','Marginal_Adhesion','SE_epitelial_cell_size','Bare_nuclei','bland_chromatin','Normal_Nucleoli','Mitoses','Class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         int64\n",
       "Clump                      int64\n",
       "U_Cell_size                int64\n",
       "U_Cell_shape               int64\n",
       "Marginal_Adhesion          int64\n",
       "SE_epitelial_cell_size     int64\n",
       "Bare_nuclei               object\n",
       "bland_chromatin            int64\n",
       "Normal_Nucleoli            int64\n",
       "Mitoses                    int64\n",
       "Class                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Change bare nuclei values to numeric only and check the numbers of NAN\n",
    "df['Bare_nuclei'] = pd.to_numeric(df['Bare_nuclei'], errors='coerce')\n",
    "print(df['Bare_nuclei'].isnull().values.sum())\n",
    "\n",
    "# Drop the lines with null values\n",
    "df = df.dropna()\n",
    "print(df['Bare_nuclei'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Attribute                     Domain\n",
    "-- -----------------------------------------\n",
    "1. Sample code number            id number\n",
    "2. Clump Thickness               1 - 10\n",
    "3. Uniformity of Cell Size       1 - 10\n",
    "4. Uniformity of Cell Shape      1 - 10\n",
    "5. Marginal Adhesion             1 - 10\n",
    "6. Single Epithelial Cell Size   1 - 10\n",
    "7. Bare Nuclei                   1 - 10\n",
    "8. Bland Chromatin               1 - 10\n",
    "9. Normal Nucleoli               1 - 10\n",
    "10. Mitoses                       1 - 10\n",
    "11. Class:                        (2 for benign, 4 for malignant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of occurrences of both types of cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total     = 683 -> 100%\n",
      "Benign    = 444 -> 65.00732064421669%\n",
      "Malignant = 239 -> 34.99267935578331%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total     = {len(df)} -> 100%\")\n",
    "print(f\"Benign    = {len(df[df.Class == 2])} -> {len(df[df.Class == 2])/len(df) *100}%\")\n",
    "print(f\"Malignant = {len(df[df.Class == 4])} -> {len(df[df.Class == 4])/len(df) *100}%\")\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "dataset_scaled = min_max_scaler.fit_transform(dataset)\n",
    "df = pd.DataFrame(dataset_scaled)\n",
    "df.head()\n",
    "dataset = df.values #returns a numpy array\n",
    "\n",
    "# Divide dataset into features and labels\n",
    "x = dataset[:, 0:10].astype(float)\n",
    "y = dataset[:, 10:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data\n",
    "seed = 9\n",
    "# Split data set into train and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x, y, test_size=0.15, random_state=seed\n",
    ")\n",
    "# Split train into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train, y_train, test_size=0.175, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Porcent</th>\n",
       "      <th>N benign</th>\n",
       "      <th>N malignant</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>60</td>\n",
       "      <td>314</td>\n",
       "      <td>164</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total</td>\n",
       "      <td>100</td>\n",
       "      <td>444</td>\n",
       "      <td>239</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dataset  Porcent  N benign  N malignant  Total\n",
       "0    Training       60       314          164    478\n",
       "1  Validation       20        60           43    103\n",
       "2        Test       20        70           32    102\n",
       "3       Total      100       444          239    683"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset dataframe\n",
    "class_1 = [len(np.where(y_train[:,0]==0)[0]),len(np.where(y_val[:,0]==0)[0]),len(np.where(y_test[:,0]==0)[0])]\n",
    "class_1.append(np.sum(class_1))\n",
    "class_2 = [len(np.where(y_train[:,0]==1)[0]),len(np.where(y_val[:,0]==1)[0]),len(np.where(y_test[:,0]==1)[0])]\n",
    "class_2.append(np.sum(class_2))\n",
    "total   = [len(y_train[:,0]),len(y_val[:,0]),len(y_test[:,0])]\n",
    "total.append(np.sum(total))\n",
    "\n",
    "table_df = {'Dataset': ['Training','Validation','Test','Total'],'Porcent':[60,20,20,100], 'N benign': class_1,'N malignant': class_2,'Total':total}\n",
    "table_df = pd.DataFrame(data=table_df)\n",
    "table_df.to_csv('divided_dataset.csv')\n",
    "table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 39ms/step - loss: 1.0116 - accuracy: 0.3518 - val_loss: 0.6986 - val_accuracy: 0.4175\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.3657 - val_loss: 0.5055 - val_accuracy: 0.4175\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.3573 - val_loss: 0.3887 - val_accuracy: 0.4078\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.3612 - val_loss: 0.3172 - val_accuracy: 0.3689\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.2634 - val_loss: 0.2675 - val_accuracy: 0.3204\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.3088 - val_loss: 0.2299 - val_accuracy: 0.8252\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.8333 - val_loss: 0.1981 - val_accuracy: 0.8738\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.8410 - val_loss: 0.1718 - val_accuracy: 0.8835\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1642 - accuracy: 0.8880 - val_loss: 0.1493 - val_accuracy: 0.8932\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.8964 - val_loss: 0.1294 - val_accuracy: 0.9029\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9117 - val_loss: 0.1135 - val_accuracy: 0.9417\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9150 - val_loss: 0.1000 - val_accuracy: 0.9515\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9378 - val_loss: 0.0889 - val_accuracy: 0.9515\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9265 - val_loss: 0.0794 - val_accuracy: 0.9612\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9560 - val_loss: 0.0714 - val_accuracy: 0.9612\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9427 - val_loss: 0.0650 - val_accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9531 - val_loss: 0.0598 - val_accuracy: 0.9612\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9426 - val_loss: 0.0553 - val_accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9411 - val_loss: 0.0519 - val_accuracy: 0.9612\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9463 - val_loss: 0.0488 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9657 - val_loss: 0.0465 - val_accuracy: 0.9612\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9580 - val_loss: 0.0446 - val_accuracy: 0.9612\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9373 - val_loss: 0.0429 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9545 - val_loss: 0.0417 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9487 - val_loss: 0.0406 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9408 - val_loss: 0.0398 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9470 - val_loss: 0.0391 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9462 - val_loss: 0.0385 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9631 - val_loss: 0.0380 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0431 - accuracy: 0.9465 - val_loss: 0.0374 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9563 - val_loss: 0.0372 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0463 - accuracy: 0.9437 - val_loss: 0.0368 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9633 - val_loss: 0.0365 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9461 - val_loss: 0.0363 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 0.9582 - val_loss: 0.0361 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9335 - val_loss: 0.0358 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9637 - val_loss: 0.0356 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9423 - val_loss: 0.0354 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9537 - val_loss: 0.0353 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9448 - val_loss: 0.0351 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9560 - val_loss: 0.0349 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9579 - val_loss: 0.0346 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9543 - val_loss: 0.0345 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9644 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9593 - val_loss: 0.0343 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9537 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9693 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9553 - val_loss: 0.0338 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9729 - val_loss: 0.0337 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9544 - val_loss: 0.0335 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9587 - val_loss: 0.0335 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9654 - val_loss: 0.0333 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9766 - val_loss: 0.0331 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9578 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9659 - val_loss: 0.0327 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 0.9738 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9623 - val_loss: 0.0327 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9625 - val_loss: 0.0326 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9655 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9717 - val_loss: 0.0322 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9635 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9556 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9680 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9652 - val_loss: 0.0319 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9676 - val_loss: 0.0317 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0416 - accuracy: 0.9522 - val_loss: 0.0317 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9706 - val_loss: 0.0316 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9682 - val_loss: 0.0315 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9735 - val_loss: 0.0314 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9587 - val_loss: 0.0313 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9646 - val_loss: 0.0312 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9624 - val_loss: 0.0312 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9606 - val_loss: 0.0310 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9650 - val_loss: 0.0310 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9595 - val_loss: 0.0311 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9597 - val_loss: 0.0308 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9677 - val_loss: 0.0308 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9657 - val_loss: 0.0308 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9638 - val_loss: 0.0308 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9459 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9641 - val_loss: 0.0305 - val_accuracy: 0.9709\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9560 - val_loss: 0.0303 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9679 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9667 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0434 - accuracy: 0.9480 - val_loss: 0.0302 - val_accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9639 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9589 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9562 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9617 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9679 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9580 - val_loss: 0.0299 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9665 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 0.9697 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9606 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 0.9742 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9566 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9694 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9655 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9712 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9688 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9617 - val_loss: 0.0293 - val_accuracy: 0.9709\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9703 - val_loss: 0.0293 - val_accuracy: 0.9709\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9588 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9722 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9694 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9542 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9720 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9554 - val_loss: 0.0289 - val_accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9553 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9643 - val_loss: 0.0289 - val_accuracy: 0.9709\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 0.9752 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9651 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9626 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9488 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0332 - accuracy: 0.9589 - val_loss: 0.0286 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9612 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9534 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9617 - val_loss: 0.0285 - val_accuracy: 0.9709\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9631 - val_loss: 0.0285 - val_accuracy: 0.9709\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9671 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 0.9633 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 00121: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Building the NN\n",
    "lr = 0.001  # learning rate\n",
    "lr_decay = 0.0005# learning rate decay\n",
    "n_mini_batch = 100  # mini-batch length\n",
    "activation_fcn = \"sigmoid\"\n",
    "optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "input_dim = x.shape[1]\n",
    "h_n = 30\n",
    "model = Sequential()\n",
    "model.add(Dense(h_n, input_dim=input_dim, activation=activation_fcn))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train and validate the model\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train[:, 0],\n",
    "    validation_data=(x_val, y_val[:, 0]),\n",
    "    epochs=200,\n",
    "    batch_size=50,\n",
    "    # verbose=0,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", min_delta=0.001, patience=20, verbose=1\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred = np.array(pred).flatten()\n",
    "erro = pred - np.array(y_test[:, 0]).flatten()\n",
    "erro = np.abs(erro)\n",
    "\n",
    "acerto = 0\n",
    "for i in erro:\n",
    "    if i < 0.5:\n",
    "        acerto += 1\n",
    "\n",
    "best_pred = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAEhCAYAAACk4QBdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAxOAAAMTgF/d4wjAAA/e0lEQVR4nO3deXyTZb7//9edpRttgdIWSkNAKMWFtYAiiojLiIrokRlxBJ16RBiX7+iDGcVzjjPjbIxHnTrOdqyj4igwLoAj7j8VRXAUQQQEWdpqaQuFsraUrknu3x93kqZQWpCmSeH9fDzySJpcufPJTdq8ua7rvm7DNE0TERERkShhi3QBIiIiIqEUTkRERCSqKJyIiIhIVFE4ERERkaiicCIiIiJRReFEREREoooj0gWcrNjYWNLS0iJdhoiIiJyAPXv2UF9f3+JjnT6cpKWlUVZWFukyRERE5AS4XK5jPqZhHREREYkqYQ8nP/nJT+jXrx+GYbBu3bpjtnvmmWcYOHAgAwYM4Pbbb6exsTHcpYmIiEgUCns4+f73v8/KlSvp27fvMdt8++23/PznP2fFihUUFhaye/dunnrqqXCXJiIiIlEo7HNOLrroojbbLFq0iMmTJ9OrVy8AfvzjHzN37lzuuuuuk359n8+HTh8UXoZhYLNphFBERNpHVEyILSkpadaz0q9fP0pKSlpsm5eXR15eXvDn6urqFts1NDRQUlKi4aEO4nQ6cbvdxMTERLoUERHp5KIinJyI2bNnM3v27ODPx5rtW1JSQlJSEj169MAwjI4q77Rkmib79u2jpKSErKysSJcjIiKdXFSEE7fbTVFRUfDn4uJi3G73d96ez+ejsbGRHj164HBExVs85fXo0YP9+/fj8/k0xCMiIiclKr5FpkyZwtKlS9m1axemafLkk09y4403fuftBeaYqMek4wT2teb3iIjIyQp7OJk1axYul4uysjKuuOKKYLf/jBkzWLp0KQD9+/fnV7/6FRdccAFZWVmkpaUxa9ascJd2TIfrPWzfd5jD9Z6I1SAiInK6MsxO/l/dQPAJ5fV62bZtG9nZ2djt9hPeZlVtI8X7DuPqHk9Kl9iTrnH48OGANUl369atDBkyBIBBgwbx0ksvHdc2fvGLXzBo0CCmTZt20vWEw8nucxEROb209P0doAkZLXDYrSEKj7d9cltg8bni4mKGDx/e4mJ0Ho+n1fkxv/71r9ulFhERkWh3WoSTGf9YzfZ9Ncfd3gTqPV4cNhsOW+vzVvr2SODpH43+TnX169ePqVOn8uGHHzJw4ECee+45fv7zn7Ns2TIaGhrIzs4mPz+f7t27k5uby/Dhw7n33nt56KGH2Lx5MzU1NRQVFdGrVy8WLVpESkoKXq+XBx54gLfffhuACRMm8Ic//EGH+IqISKcRFRNio00gjnTEiNe+fftYtWoVCxYs4NFHH6VLly58/vnnrFu3jiFDhvDggw+2+LxVq1bx3HPP8fXXX5Oenk5+fj4ATz31FKtXr+aLL75g3bp1FBUV8fjjj4f9fYiIiLSX06Ln5Lv0bGzaWUmc086AtMQwVNQkNzc3eKTLv/71LyorK1m8eDFgzVHp169fi8+bOHEiPXr0AOD888/nq6++AuD9998nNzeX2Fhrrsztt9/OX//6V+bMmRPW9yEiItJeTotw8l04bLZ2m3PSmsTEpvBjmiZ//vOf+d73vtfm8+Li4oK37XY7Hk/LRxbpcGoREelsNKxzDA67gcfn69DXvO6663j88cepqbHmx9TU1LBp06YT2sZll13G888/T0NDAx6Ph6effvq4wo6IiEi0UM/JMThsBl6fic80sXVQ78OcOXOor6/nvPPOC/Z4zJkzh3POOee4tzFz5kyKiorIyckB4OKLL+bee+8NR7kiIiJhoXVOjmHHwVr2VddzVq9knA51MLVF65yIiMiJaG2dE33rHkPgEOKOHtoRERE53SmcHENgIbZGX6fuWBIREel0FE6Owek/s25HHLEjIiIiTRROjkHDOiIiIpGhcHIM7X1+HRERETk+CifH4AgM62jOiYiISIdSODkGm83Abhh4vBrWERER6UgKJ61w2G3t0nNy1VVX8Ze//OWo+4cNG8aSJUtafM5zzz3HddddB8CaNWuYOnVqi+2qq6tPeon6N954g7Fjx3LVVVdpwTYREYk4rRDbCofNoN5z8j0nt912G3PnzuXuu+8O3rdmzRrKy8u55ppr2nz+qFGjeOmll066jmOZNGkSkyZNCtv2RURETsTpEU4W3ggHvj3hp/Xx+vD5TEynnWP2TXQ/A256sdXtTJ48mTvuuIMNGzYwdOhQAJ599lkmT57M9773Paqqqqirq2PChAn86U9/wmZr3qH10Ucfce+997Ju3ToA8vPzeeyxx0hMTOT6669v1nbatGls3bqVhoYG+vTpwzPPPEOvXr0AePPNN3nooYdoaGjAMAzy8/M577zzWn3OCy+8wKOPPmrtjz59eOqpp8jMzDyBvSgiInJiwj6sU1BQwNixY8nOzmb06NEtnsjO5/Pxs5/9jMGDB3PmmWdy22230dDQEO7S2hQMJCc5suN0Orn55pt59tlnAairq+Of//wnP/3pT3n99df54osv2LBhA8XFxbz88sutbmvjxo388pe/5OOPP+bLL7+ktra22eN//OMfWbNmDRs2bGDcuHE89NBDAGzbto1bb72VF154gfXr17N69WrOPPPMVp+zceNG7rvvPt5++202bNjA2LFjmTFjxsntDBERkTaEvedk1qxZzJw5k9zcXBYtWkRubi6rV69u1uaZZ55h7dq1rF27FqfTycyZM3niiSe477772qeINno2jmV/VR27q+oYmJ5EfMzJnS/mtttuY/z48TzyyCMsWbKEs846i759+3LfffexcuVKTNOkoqKCwYMHc+ONNx5zO8uWLePKK68kIyMDgDvuuIPf//73wccXLlzICy+8QF1dHXV1daSmpgLw3nvvMXHixGAgcTqddO3atdXnfPjhh0ycODHYU3LnnXfy61//Gq/Xq/PniIhI2IS156SiooI1a9Ywffp0AKZMmUJpaSmFhYXN2q1fv57LLruMmJgYDMPgyiuv5IUXXghnacelPRdiO/vss8nKyuL111/n2Wef5bbbbiMvL4+KigpWrVrFhg0buOmmm6irqzuh7YZOhl25ciV/+tOfeOutt9i4cSN5eXltbu9EnnOyE29FRESOR1jDSWlpKRkZGTgcVgeNYRi43W5KSkqatRs5ciRLly6lqqqKxsZGXn75ZYqLi1vcZl5eHi6XK3iprq4OW/0Oe/suYR+YGPv5558zdepUDhw4QK9evYiLi2PXrl288sorbW7jkksu4Z133mHXrl0APPnkk8HHDhw4QFJSEj169KChoYH8/PzgY1dccQXvvvsuW7ZsAaCxsZHKyspWnzNhwgTeeecddu7cGXytSy+9VL0mIiISVlFxKHFubi4TJ05k/PjxjB8/nuzs7GCgOdLs2bMpKysLXhITE8NWV3svYT916lS2bt3KD37wAxITE7nnnntYtWoV55xzDjfffDOXXXZZm9sYPHgwDz30EOPGjWPEiBHExsYGH5s4cSKDBg1i0KBBjBs3juHDhwcfy8rKYt68eUybNo2ePXty7rnnsnXr1lafM3jwYB599FEmTpzI0KFDWbFiBX//+9/bZV+IiIgci2GaZtiWQK2oqCArK4v9+/fjcDgwTZOMjAxWrlxJVlbWMZ/34osv8te//pUVK1a0+Roul4uysrJm93m9XrZt20Z2dvZJ/S+/3uNl665DpCXFktE1/jtvJ9o89dRT9O7du10PH26vfS4iIqeHlr6/A8Lac5Kenk5OTg7z588HYPHixbhcrqOCSV1dHQcOHABg7969PPzww9x///3hLO24OE7BMxPPmjWLuXPn4vV6I12KiIhIi8J+tE5+fj65ubnMnTuX5ORk5s2bB8CMGTOYPHkykydPprKykosvvhibzYbP5+Oee+45rsXJws1uM7AZBo2n0BL2oXNKREREolHYw8mgQYP49NNPj7r/6aefDt7u2bMnmzdvbrfXDBxV0h4jVg67oZP/HYfAvtYRPSIicrJOyRVibTYbTqeTffv20aNHj5P6wrQDDR6vhkFaYZom+/btw+l0HrW6rYiIyIk6JcMJEDxkef/+/Se1nX3V9dQ1+jAq41GnwLE5nU7cbnekyxARkVPAKRtOYmJiyMrKwufzndTwzkOvb+Ll1TtZMWcCPbrEtGOFpw7DMNRjIiIi7eaUDScBJ/ul2b1LHPVek/01jaQnnzqHE4uIiEQr/Xe3DWmJVm/J3kORPxGhiIjI6UDhpA2pidYKrHur6yNciYiIyOlB4aQNqUkKJyIiIh1J4aQNgZ6TPQonIiIiHULhpA2pmnMiIiLSoRRO2pAY6yDWYdOwjoiISAdROGnJro3w7v/Aro0YhkFqYqzCiYiISAdROGlJZSl8+hcoXwdYk2IVTkRERDqGwklLkjOt66qdgLXWyb7qBnw6AaCIiEjYKZy0JBBOKssA64gdj8+ksrYxgkWJiIicHhROWpKQAo64YM9JenIcALuq6iJZlYiIyGlB4aQlhgHJvaFqBwCZ3axwsvNgbSSrEhEROS0onBxLcmYwnPTuZp3wb2elek5ERETCTeHkWJIzoa4S6qubwol6TkRERMIu7OGkoKCAsWPHkp2dzejRo9m0adNRbXw+H7Nnz+bss89m6NChTJgwgcLCwnCX1rquTUfs9O6qcCIiItJRwh5OZs2axcyZM9m2bRtz5swhNzf3qDZLly7lk08+Yf369WzYsIFLL72U//7v/w53aa1L7m1dV5URH2One4KT8oMa1hEREQm3sIaTiooK1qxZw/Tp0wGYMmUKpaWlR/WKGIZBfX09dXV1mKZJVVUVLpcrnKW1Ldn/+v4jdnp3i2eHek5ERETCzhHOjZeWlpKRkYHDYb2MYRi43W5KSkrIysoKtrvmmmv48MMP6dWrF0lJSWRmZrJ8+fIWt5mXl0deXl7w5+rq6vAUH+g5qWyaFLtl1yG8PhO7zQjPa4qIiEh0TIhds2YNGzduZMeOHezcuZNLL72UH//4xy22nT17NmVlZcFLYmJieIrqGug58YeTrnF4fSYVhzS0IyIiEk5hDSd9+vShvLwcj8cDgGmalJSU4Ha7m7V7/vnnueSSS+jWrRs2m40f/ehHfPjhh+EsrW3x3f0LsR1xOLHmnYiIiIRVWMNJeno6OTk5zJ8/H4DFixfjcrmaDekA9O/fn2XLltHQ0ADAG2+8weDBg8NZWtsMw7/WSdOcE9AROyIiIuEW1jknAPn5+eTm5jJ37lySk5OZN28eADNmzGDy5MlMnjyZu+66i82bNzNs2DCcTie9evXiySefDHdpbUvuDeUbAIUTERGRjhL2cDJo0CA+/fTTo+5/+umng7djY2P5+9//Hu5STlxXFxSvgPpD9NYS9iIiIh0iKibERq3gWic7SU+Kw24ztIS9iIhImCmctCY5sErsDuw2g17Jceo5ERERCTOFk9YEwkll4OzE8QonIiIiYaZw0pqQYR2AjG5xHKhppLbBG8GiRERETm0KJ60JLsRWBoQcsVOp3hMREZFwUThpTXAhNq11IiIi0lEUTloTWIgtOOdEhxOLiIiEm8JJW5J7N8056aol7EVERMJN4aQtXV1QX+lfiE3DOiIiIuGmcNKWkCN2kuMcJMY6NCFWREQkjBRO2hJc66QMwzDo3S1OwzoiIiJhpHDSluAqsU3zTnYerMU0zQgWJSIicupSOGlL16Yl7ME6nLje42P/4YYIFiUiInLqUjhpS3LzcNJ0OLGGdkRERMJB4aQt8d3BER9c6yRwxM4OHbEjIiISFgonbTGMFtc6KdcROyIiImGhcHI8umaGDOtorRMREZFwUjg5HsmZUF8FdVX07BqLYWjOiYiISLiEPZwUFBQwduxYsrOzGT16NJs2bTqqzbx58xg+fHjwkpqayvXXXx/u0o5ft77W9YFviXXYSUuM1ZwTERGRMAl7OJk1axYzZ85k27ZtzJkzh9zc3KPa3Hrrraxbty546dWrF9OmTQt3accvLdu63lsAQGb3eMoO1ESwIBERkVNXWMNJRUUFa9asYfr06QBMmTKF0tJSCgsLj/mcVatWUVFRweTJk8NZ2olJ9YeTPVsB6J+ayN7qBiprGiNYlIiIyKkprOGktLSUjIwMHA4HAIZh4Ha7KSkpOeZznnnmGW6++WacTmeLj+fl5eFyuYKX6urqsNTeTI8swIC9VjgZkN4FgKK9HfDaIiIip5momhB7+PBhXnzxRW677bZjtpk9ezZlZWXBS2JiYvgLc8ZD977BYZ0BadZrFlUonIiIiLS3sIaTPn36UF5ejsfjAcA0TUpKSnC73S22f+WVVzjnnHM4++yzw1nWd5OaDfsKwethQJrVc/LN3sMRLkpEROTUE9Zwkp6eTk5ODvPnzwdg8eLFuFwusrKyWmz/zDPPtNprElGp2eBtgIPbcad0wW4z1HMiIiISBmEf1snPzyc/P5/s7Gwefvhh5s2bB8CMGTNYunRpsN3WrVtZt24dU6dODXdJ303aIOt67zZiHDb6piRQtEfhREREpL05wv0CgwYN4tNPPz3q/qeffvqodocOHQp3Od9d6BE7g66kf1oiH22toNHrw2mPqqk7IiIinZq+VY9XIJzs3QbAgLQueHwmpfu13omIiEh7Ujg5Xgkp0CUtJJz4j9jZo0mxIiIi7Unh5ESkZsOebWCaTWudaN6JiIhIu1I4ORGp2VBfCdW76Z+qtU5ERETCQeHkRIQcsdO9SwwpXWK01omIiEg7Uzg5EakDrWv/OXYGpHWhsKIa0zQjWJSIiMipReHkRKQ29ZyANSm2sraR/YcbIliUiIjIqUXh5EQkZ4Kzy1FH7GhoR0REpP0onJwImw1Ss6wjdoD+/nPsaFKsiIhI+1E4OVGpg+DQTqirClnrROFERESkvSicnKg0/0qx+wpwdY8nxm7TQmwiIiLtSOHkRAXPsbMNh91G3x4JfKOeExERkXajcHKigkfsBA4nTqRkfw31Hm8EixIRETl1KJycqJT+YNhhbwEAA9K74DNh+z6dAFBERKQ9KJycKEeMFVAqNgMhJwDUETsiIiLtQuHku+g9AvYXweF99NdaJyIiIu1K4eS7cJ9nXZeuYoB/rZMtuw5FsCAREZFTh8LJd9FnjHVd+hlJcU6y0hNZu/1AZGsSERE5RYQ9nBQUFDB27Fiys7MZPXo0mzZtarHdV199xcUXX8xZZ53FWWedxZIlS8Jd2neXfhbEJkPJKgBGuruz42AtuyrrIlyYiIhI5xf2cDJr1ixmzpzJtm3bmDNnDrm5uUe1qamp4dprr+W3v/0tmzdvZuPGjYwbNy7cpX13Nju4RsPOL8FTz8h+3QH4Qr0nIiIiJ+2kwsnhw61PAq2oqGDNmjVMnz4dgClTplBaWkphYWGzdgsXLmTMmDFceOGFANjtdtLS0k6mtPBzjwFvPexcx6i+VjhZs31/hIsSERHp/NoMJ+eff37w9s0339zssbZ6N0pLS8nIyMDhcABgGAZut5uSkpJm7b7++mtiY2OZNGkSw4cP55ZbbmHPnj0tbjMvLw+XyxW8VFdH6BDePoFJsZ9xRmoXUrrEqOdERESkHbQZTurqmuZRHDlfxDTNdinC4/Hw/vvvk5+fz5dffklmZiZ33HFHi21nz55NWVlZ8JKYmNguNZww1yhrMbaSVRiGQY67O5t2VlHT4IlMPSIiIqeIExrWOTKMGIbRavs+ffpQXl6Ox+MJPr+kpAS3292sndvtZsKECWRmZmIYBtOnT+ezzz47kdI6XkwX6DUESleBaTKqX3e8PpP1pZWRrkxERKRTazOchAaQtsLIkdLT08nJyWH+/PkALF68GJfLRVZWVrN2N9xwA6tXr6aqqgqAt956i2HDhp3Qa0WEewzU7IV9RcF5J19o3omIiMhJcbTVYMOGDaSkpABQVVUVvG2a5nHN98jPzyc3N5e5c+eSnJzMvHnzAJgxYwaTJ09m8uTJuN1u/vu//5uxY8dis9nIzMzkqaeeOpn31TH6nAernoTSzxg8+IfE2G2s0bwTERGRk2KYbUwc2b59e6sb6Nu3b7sWdKJcLhdlZWWRefGqnZB3Foy4Ga79C9f/7RMKK6pZ94vvYbOdWC+TiIjI6aS17+82e05aCh8HDx6kW7duJ11Yp5fcG7q6rXknwKh+KawtOUjhnmqyeyZFuDgREZHOqc05J3/84x/ZvNk6A6/P52PSpEmkpKSQlpbGp59+GvYCo577PNi7DWr2k+P2r3dSrKEdERGR76rNcPL0008zYMAAAF555RWKioooLy/nueeeY86cOWEvMOr1aToJ4EgtxiYiInLS2gwnDoeDmJgYAD744ANuvvlmevbsydVXX82hQzoTL27/SQBLPiUtKZZ+PRJ0EkAREZGT0GY48Xg8wfVNPvnkE8aOHRt8rLGxMXyVdRbpZ0N8ChQuA2Bk3xSK99Ww51B9hAsTERHpnNoMJ5dccglTp07l7rvv5tChQ8Hz3+zatYvY2NiwFxj1bHbIvgJ2fwUHS4NDO1rvRERE5LtpM5zk5eVx3nnnERMTw7vvvhs8T05BQQE//elPw15gp5A90bre9g5j+lvrwPy7aF8ECxIREem82jyU+P777wesRdf+/ve/H/X4TTfd1P5VdTYDLgGbE7a+zRmjZ5DZLZ4VBXsjXZWIiEindFyHEn/yySckJyfTtWvXoy4CxCXDGeOgeAVGQzXjBqby7d7DlO6viXRlIiIinU6bPScffPABzz77LAsXLuSGG27gP//zP4OHFkuI7CuhaBkULePCgaN5cXUpKwv38sNz3W0/V0RERILa7DmZMGECL7zwAl988QVut5tp06YxYcIEVq1a1RH1dR6D/PNOtr7DBQNSMQxYqaEdERGRE9ZmOAlITk7m2muv5dprr2XLli1s2bIlnHV1Pt3c0HMwFLxL93g7QzK7srJwL15fq6cuEhERkSO0GU68Xi+vvvoqkyZN4vLLL8dut7N27Vp+9KMfdUR9nUv2RKjZB2WrGTcwlcraRjbuqIx0VSIiIp1Km3NOMjMzcbvd3HrrrVxwwQUA7Nmzhz179gAwdOjQ8FbYmQy6ElY8Blvf5sKsn/DXD4tYUbCHYX26RboyERGRTqPNcBIXF8eePXt45JFHMAwjuFosgGEYfPPNN2EtsFPpnQNd0mHbO+RM+AUJMXY+LtjL3ZcMjHRlIiIinUab4aS4uLgDyjhF2GzWarFfvkBs1XbOOyOFlYV7qa73kBjb5q4WERERTmBCrBynQVdZ118vZdzANBq9Jqu+0WqxIiIix0vhpL1lXQpx3WD9i4zL6gGg1WJFREROQNjDSUFBAWPHjiU7O5vRo0ezadOmo9p89NFHxMfHM3z48OCltrY23KWFhyMWBk+BPZvJ8hXRKzmOFQV7Il2ViIhIpxH2cDJr1ixmzpzJtm3bmDNnDrm5uS22GzRoEOvWrQte4uPjw11a+Ay3zjdkrH+JCwemUrRHS9mLiIgcr7CGk4qKCtasWcP06dMBmDJlCqWlpRQWFobzZSMvcyT0yIKvXmHiWdbQzptflUe4KBERkc4hrOGktLSUjIwMHA7rSBXDMHC73ZSUlBzVtqioiJycHEaPHs3f/va3Y24zLy8Pl8sVvFRXV4et/u/MMGDYjVCzl/G29STHOXht3c5IVyUiItIpRMWE2JycHMrKyli7di2vvvoqTz75JC+//HKLbWfPnk1ZWVnwkpiY2MHVHqehNwLg3PgSVw3JYHN5FQW7D0W4KBERkegX1nDSp08fysvL8Xg8AJimSUlJCW538zP1Jicn07VrVwBcLhc//OEPWbFiRThLC79ufaDfONj6Nv9xVhcAlq5X74mIiEhbwhpO0tPTycnJYf78+QAsXrwYl8tFVlZWs3bl5eX4fD4ADh06xBtvvMGIESPCWVrHGPZD8DYwuvoj0pNieW3dzmYr7IqIiMjRwj6sk5+fT35+PtnZ2Tz88MPMmzcPgBkzZrB06VLACi1Dhgxh2LBhjBkzhssvv5xbb7013KWF39mTwZmAbcOLXDOsNyX7a1hXejDSVYmIiEQ1w+zk/5V3uVyUlZVFuoxjWzITNrzE1u8v44r5u7j1gn788ppzIl2ViIhIRLX2/R0VE2JPaTm3AJBdtpgzUrvw+vpyvL5OnQdFRETCSuEk3PpeAKnZGOsXct2QHuytrufTIp1rR0RE5FgUTsLNMGDkrVB7gKkJawFYun5HhIsSERGJXgonHWHYjWCPpde2hQzOTOatr3ZR0+CJdFUiIiJRSeGkIySkwODrofQzZp1ZT3W9h9e15omIiEiLFE46ykjr0Ograt8mIcbOglVHL+EvIiIiCicdp8+5kH4OMZte5vtDU9hQVsmGsoORrkpERCTqKJx0FMOAUbdCfRUzU9YBsFC9JyIiIkdROOlIQ28AZwKuwoUMy0zmtXU7qaprjHRVIiIiUUXhpCPFdYWhU2Hnl9yTvY/aRi+vfanDikVEREIpnHS08+8CDC7a+0+S4hwsWFWikwGKiIiEUDjpaKkDYdBVOAreYebZXrbsOsTakgORrkpERCRqKJxEwtj/B8DN5usA/OPf2yNZjYiISFRROIkE9xhwjabbtsVc3d/OGxt2UrKvJtJViYiIRAWFk0gwDKv3xFvPf/VYic+EJz8uinRVIiIiUUHhJFLOnATdzyCzcD5j+sSxaE0Zu6vqIl2ViIhIxCmcRIrNDuffhVF7gIdcX9Lg9fH0im8iXZWIiEjEKZxE0vBpkNCDQd/MY3DPOBasKuHA4YZIVyUiIhJRYQ8nBQUFjB07luzsbEaPHs2mTZuO2dY0TS655BK6desW7rKiQ0wCnH83RmUZvzljIzUNXp77d3GkqxIREYmosIeTWbNmMXPmTLZt28acOXPIzc09ZtvHH3+cAQMGhLuk6HLu7RDfneHFz9A/JYbn/l1Mdb0n0lWJiIhETFjDSUVFBWvWrGH69OkATJkyhdLSUgoLC49qu2nTJv71r3/xwAMPhLOk6BObBGPuwji4nblZm6msbeQf6j0REZHTWFjDSWlpKRkZGTgcDgAMw8DtdlNS0vxsvI2Njdx+++3k5+djt9tb3WZeXh4ulyt4qa6uDlv9Hea8mRDXlfNK59G3Wwz5y4uorNUJAUVE5PQUFRNif/WrX3H99ddz1llntdl29uzZlJWVBS+JiYkdUGGYxXWFMXdiHPiGx84soKrOw1Na90RERE5TYQ0nffr0oby8HI/HmkNhmiYlJSW43e5m7ZYvX86f//xn+vXrx4UXXkhVVRX9+vVjz5494Swvupw3C2KTGVX6DIPS4nl2ZTF7DtVHuioREZEOF9Zwkp6eTk5ODvPnzwdg8eLFuFwusrKymrVbsWIF27dvp7i4mJUrV5KcnExxcTFpaWnhLC+6xHeH836Msa+QR84qpLbRy18/PHpujoiIyKku7MM6+fn55Ofnk52dzcMPP8y8efMAmDFjBkuXLg33y3cuY+6A2GSGFv4fOZldWLBqO6X7dc4dERE5vRimaZqRLuJkuFwuysrKIl1G+1n+CHz4OwrO+x2XLz+D74908dgPhkW6KhERkXbV2vd3VEyIlRBj7oCEHgzc/DfG909iydoytuyqinRVIiIiHUbhJNrEJsG4n0LVDn7vXo0J/Pr1r+nkHVwiIiLHTeEkGo26DZJ603vD35g2PIV/F+3j3U27I12ViIhIh1A4iUbOOBh/P9Ts5b9SlpMU6+B3b31NXaM30pWJiIiEncJJtBoxHbqfQZc1f+O+camU7q/l6RXfRLoqERGRsFM4iVZ2J1zyINRXMq36OfqnduGvHxZRXlkb6cpERETCSuEkmg2eAmdchH3d8zw6pp7aRi8Pv70l0lWJiIiElcJJNDMMuOoPYHMy8qvfcNmgHry2bicfbqmIdGUiIiJho3AS7dKy4YKfwO6v+EPfVSTFOnhgyQYqa3TWYhEROTUpnHQG434G3dx0/ewRfndZCrur6vn1G19HuioREZGwUDjpDGIS4MpHoaGaa8r/wvjsNBavLWPZFq19IiIipx6Fk85i0EQ4cxLG1//ij0NLSIpz8MDirzS8IyIipxyFk87k6jyI7073ZXP47eW9qDhUz89f26il7UVE5JSicNKZJPWEqx6Dmr1M3vk4l5/dk6Xrd/LPz0sjXZmIiEi7UTjpbAZPgbOuwdj0Kk8M/hZX93geen0TG3dURroyERGRdqFw0tkYBlz9OCT0IOG9+3nqP/qACXctXEtVneafiIhI56dw0hklpsHVf4Da/Zy95kEevHoQ2/fVMGfRBs0/ERGRTk/hpLM65z9g6I2w7R1u9v6Lq4dm8PbGXTz1sU4OKCIinVvYw0lBQQFjx44lOzub0aNHs2nTpqPafPrppwwfPpzhw4dzzjnnMGvWLOrr68NdWuc3KQ/SzsJY9hseHXmQ7J6JPPzOFt7dtCvSlYmIiHxnYQ8ns2bNYubMmWzbto05c+aQm5t7VJthw4axevVq1q1bx1dffUVFRQV/+9vfwl1a5xfTBaa+AM4uJCydybwpfUhJiOHeF9dpgqyIiHRaYQ0nFRUVrFmzhunTpwMwZcoUSktLKSwsbNYuISEBp9MJQENDA7W1tRiGEc7STh2pA+Hav8DhPWS+fydPTR+K1zS57R+r2VVZF+nqRERETlhYw0lpaSkZGRk4HA4ADMPA7XZTUlJyVNvi4mKGDRtGamoqXbt25c4772xxm3l5ebhcruCluro6nG+hczjnOhhzJ5R8ysivH+XR7w9ld1U9M55fTXW9J9LViYiInJComRDbr18/1q9fz65du6ivr2fJkiUttps9ezZlZWXBS2JiYgdXGqUu/zX0Gwer/8619W9y72UD2bijiv98bjU1DQooIiLSeYQ1nPTp04fy8nI8HuvL0TRNSkpKcLvdx3xOYmIiN954IwsWLAhnaaceuxNueB56ZME7c7jHXcytF/Tj82/3c/vza6hr9Ea6QhERkeMS1nCSnp5OTk4O8+fPB2Dx4sW4XC6ysrKatSssLKSx0VpArKGhgVdffZWhQ4eGs7RTU0IK3PQyxCZjLPpPfnEuTB/j5pPCfcx64QvqPQooIiIS/cI+rJOfn09+fj7Z2dk8/PDDzJs3D4AZM2awdOlSAJYtW8aIESMYNmwYI0aMoGfPnvz85z8Pd2mnph4DYOp88NRhLLyRX0/owQ2jXCzftoc7569VD4qIiEQ9w+zkS4q6XC7KysoiXUb0+XIBvHYnpJ2J95Y3uO/tHSxZu4Nzz0jh77eMomu8M9IViojIaay17++omRAr7WzENLhiLuzZgn3B9Tw2qW9wDsrU/E/ZXaXDjEVEJDopnJzKzr8LJvwP7NqAbeEN/OJ7bu6fOIgtuw4x5f/+zTd7dBi2iIhEH4WTU91F98EF90LZ5xgLb+TOMek88v2hlFfWce1fP+H9r3dHukIREZFmFE5OdYYBlz0E590B21fCvKu4IdvBvNzR2G0GM55fw2PvbsXr69RTj0RE5BSicHI6MAyY+Hu45Oew+yt45nIu6r6fN/7fhQx1deUvHxaSO+9z9lbrZIsiIhJ5CienC8OAi34G1/0fHCqHZ76Hq3ItL886nx+e62ZFwV4uz1vOa+t20MkP4BIRkU5O4eR0M/wma6E2nwf+MZm4z57g99edw19vysFmGNzz4jpuf36NThooIiIRo3ByOsq6FGZ8YJ3R+INfwcIfcPUAJ+/NHs+1w3vz/uYKLs9bzjMrv6XR64t0tSIicppRODldpZ8Jt38II6ZD4fvw5IWk7P43T9w4gqdvGUVyvJPfvPE1Vz6xgo+37Yl0tSIichrRCrEC61+EN2ZD42EYPQMu+xW1Rjz5Hxfx5PIi6hp9XHJmOvdcOpBhfbpFuloRETkFtPb9rXAilv3fwmt3W4cbd+sL1/0N+l3IjoO1/P6tzbyxoRyAC7NSuWtCFmP6p2AYRoSLFhGRzkrhRI6PzwefPwXvPwSeWjj7WpjwIKRls3XXIf7vo0KWrt+Jz4Shrq7cPKYv1wzrTZzTHunKRUSkk1E4kROzrwj+vwdh61tg2KwjfMY/AN36sH3fYZ76+BuWrN1BbaOXrvFObhjl4vsj+zCoV1KkKxcRkU5C4US+m9LP4f1fWUM9Nifk3AwXzoZufaiqa2TxF2W88Nl2vtlzGICB6YlMGtqbScMyGJCWGOHiRUQkmimcyHdnmlC0DD6cCzvWWCFlxDS44B5I6Y9pmqz6dj+vr9/J2xt3sf9wAwD9U7sw4cx0Lj0znVH9Uohx6MAwERFponAiJ880oegD+Oh/oexz676+F1qHIp89GWK64PH6+HfRPt7eWM6yLRXsrrKWw0+IsZPj7s65Z6Rw7hkpDHN1Iz5G81RERE5nCifSfkwTvv0YvngOtrwB3gaISYJBV1oTaLMuBWc8pmnydXkVyzZX8EnRXr4sOUi9x1rQzW4zyEpLZHBmVwZnJnNmr2SyeybSIzE2su9NREQ6jMKJhEfNfti4GNYthJ1rrfucXWDg5ZB9BWRdBonpANR7vGzcUcmqb/ezvvQgG3dUseNgbbPN9egSw8CeifTr0QV3jwT6pnTBnZJAZvd4uic4deiyiMgpJKLhpKCggB/96Efs3buXrl278txzz3HOOec0a7Ns2TIeeOABqqurMQyDq6++mocffhibre15CgonUeJgCWx+Hb5eCqWrAP/HKmMY9J8ArtGQORKSM4JP2X+4gY07Ktm2+5D/Uk1hRTXV9Z6jNh/vtNO7Wxy9u8WTnhRHz+RY0pNiSUmMpXuCk+4JMXRLcJKaGKtDm0VEOoGIhpNLLrmEW265hdzcXBYtWsT//u//snr16mZtvvzyS7p27Ur//v2pq6vjsssuY8aMGeTm5ra5fYWTKFS9x5qfUvCedV17oOmxpN6QmQO9hlrBJWMoJGVYZ00GTNNk/+EGtu+voWRfDaX7a9hZWUvZgVp2HKxlV2UdNQ3eVl++S4yd1KRYUrrE0DXeSXKck+R4B0lxThJjHSTFOUiMddAlNvTaTpdYBwkxDrrE2HHYNYFXRCScIhZOKioqyMrKYv/+/TgcDkzTJCMjg5UrV5KVlXXM5919992kpqby0EMPtfkaCidRzueFis3WkT47voCyL2DPFjBDAkZsV+skhKnZkJplrVDbrS90c1vDQkcM51TXe9hdVcfuyjoO1DRysLaBgzWN7D/cwL7qevYdbmDPoXr2H26gqq6RusYTP3lhjMNGQoydeKd1iXPaiXPa/Nf+2w47sf7bgXbxMdZ9sQ6b/2In1tl0Oy7kdkxoG4cNm03DViJy+mjt+9sRzhcuLS0lIyMDh8N6GcMwcLvdlJSUHDOc7Nq1i0WLFvHGG2+0+HheXh55eXnBn6urq9u/cGk/Njv0GmxdRuZa9zXWwu6vYdd6KN8Ae7fB3gIrwBzJHgtJvazeleQMSOxFYpJ1GZDYEzJ6W4/HJh8VYgIaPD6q6hqprvNQXe/hUJ2HQ3WNHG7wUF3v5XC9h8P11mM19V6qGzzU1HuobfRS2+ijtsF6bG+1l7pGL3UeHw2e9j9bc4zdH1acNuu2006M3YbTYVjXdhsxDuuxGEfTz067gdP/uNNuIybws8OGw2YE2zpsBg67gd1mw+m/P84fpOKcdv/zjeB27TYDp82G3W5Y99sUoESkY4Q1nJyoqqoqrrnmGu6//35GjRrVYpvZs2cze/bs4M8ul6ujypP24owH10jrEqr2oLU67cHt1hyWg9uhsgwOlcP+Iij9rJVtdoGknhCTCDFdrNeI6QJx3YiJ70ZqXDdS47paISY2CRKSoHui9byYLhCTYN22O48ZckL5fCb1Hp8/rHipa/RR2+ClttEKMA0eH/UeL/UeH/WNTbeDj3kD94e2s7bT9LiXBq+PmlofjR6TBq/1WIPHR4O3/cPR8QgEHIfNCi8Om4HdZvh7h6yeIafdhtNm8wchIxiMnA4rFDlCgpLDFrhtBSOHzYbNAJvNwDCs1wsNZU67zf88fw12A7th/WyzGdgMA7vN+o9QoE0gcDnsRrNt2IPtrW0oeIlEj7CGkz59+lBeXo7H4wkO65SUlOB2u49qe+jQISZOnMi1117bLHzIaSS+W8uhJcDTAIcr4NAu/6W86bpqJ1RXQF2ldV9jLTRUE5yYe7wMOzgT/OHGH1hiEvz3JQRv22K6EO9MID401Ngc1sUeY7WL72KFJWe81QPkiAFHQlOAOomjj0zTpNFr0uj14fFawaUx5NLg8T/ma7rt9YVc+0zqG5sCU70n9PkmDR6rncdn/ewJ3O9v4/WZ/setxxq8PuoafVTWNlLf6MPnr8/j9eHxv66vExwXGAg5gdBlXduCPwfuwwCbYWDgvzasQGQAjkDvU0jvVSA02W0GViuLYfh7zPy9ZQ67LSQ0WdsOFQh79iNqDAQz0wQTE9Mk5DWtGgI12kJqD/xsD+lhiwmp2TBarjn09YFmnyOHzSAx1kGif26XzTDw+kx8ponPbAq46omT1oQ1nKSnp5OTk8P8+fPJzc1l8eLFuFyuo4Z0qqurmThxIhMnTuTBBx8MZ0nSmTlioKvLuhwPnw/qq6DuoNUrU18F9YesS12VFV4aa6DhsP92rf9SAw010HjYuq7Z13S/r7F93othh7iuEJdsBRd7jBVw7E7/7RhwxPpDj7Mp/DjjwRmP4exCjDOemMD9hs1q44j3t4kDR5y17Xhn0/YccdbjjljrOU0FWW2O4wi57yo0HAVCjSfkdqPXCkOmifVF5sMfrnzBXiOrrdXO4zXxmk0hyesPQNaXoNnU1uujISQoNXh9eLw+vD6rbSBoBbYTeK7PH86OfNzjNYMBIPB8Eysw+kzrfTYEQ6IvuC2vaT1Hmhj+oGQPCUK2kMBktxnNAlUgMNlC77OFBK7Q8HVE7gkGOSOw3eaPB+4PvE7T9q0QZ/ffZwTCKIFamm43LXcQ+g/dFDQDF4e96TWatyT4npteLxAim/ZL4H0GAqbhv03w/qb3Z9C0DXvIew/UGni8Need0YO0pI5dhyrswzr5+fnk5uYyd+5ckpOTmTdvHgAzZsxg8uTJTJ48mSeeeILPP/+cw4cPs2TJEgB+8IMf8D//8z/hLk9OZTab1RsT3w26t9M2vY1WmAmGGH+o8TZawcXnBU9902MNNf7H68FTZ/X+NFRbPTx1lVZw8jZaQajOY7XzNlj3eerbLwwdL7s/wDhig0HIugR6jvzDYMGQ428L1gJ9mFjdCramniSbExwx2O2x2B2xTSEpcHHGWaEqNq75/faoGnVuF0cef+AzoTEwxOf1WoErEIaOCjMmXh8hAc8KWB6fD58PvKbZ7IvJNAmGq0av9W/jM637rW2bwZ4Wq5fLpMFjDSUGglsgVDV/D4SEPytMBuYuxTpteHxmcH5XdZ0Hk6ZeHJthNIXRkOf7QoJeIFxat5uHvqYQaO0LMyScmv73FGh7pGCI9e+T5nvWv18C7zck5HaGHr9wWzjjvA4PJ1qETSSamSb4PFZY8Tb4g4+/R6exxnrM57WOfvJ6wBPS+9NYZ4WbYNip8z+/1rod+qtv+pq276nzt6m1ttFY09Sb5Kk9dq3tzbA39QoZhv/a3hR8DLv/Pv/F7vCHpySITbR6ggwDAkMSRiAw2ZuG3xxxVo+cPTbkMXvT9m3+1wj2ZvmvDZu1XcOw2gXCnCO26XHDbj3u8/r/DRqsfy9ngjXvKTbJP7wXsq3Av7kZMqco+B6Ntv+LK+0uEOJ8ZlNgDPxs4r/253KfaYb0WFg3QkPOkT11Vnsj2HsRCFbBHrmQYTpfaEgzm4JbIFiZBEKV1RaaemV8/uDm9TU9P/C4abb9sTr3jBRSw7CCd8SO1hGRk2QYTcM9JES6GmuorLEmJMD4Aw+EBAHT+kIOBCefvxfI29DU3lNnBR9PbQs/B9rVWdsIfFmbXuva523aPoHHfFY4qz8EVeXWtbeBE55zFO3ssSE9WSFhKNgjFd/UM2UY/n8D/79DKJu9+TwqR1xT2LPZQoKZ/zq43z3W7dDhRkecFbJik6z5VIbNH4obrfaB4dLAv22gbeAS2jtnczav86ixGf8Qpc0Z1iHI5iX4h28w9IXZgbSvReT42WxWr0RsYqQrOXE+f8AJfGEHe5P8w22hjwUCkOm/DvRceeut26avaRjL5w3ZTl3I4/5LoJfG7rS+7Btrm+Y/NRy2thHsxTKb96QEXiMQDjz1Ib1j/mDXUN0U8DwNLfduhc4vCg6/dXLNepxCro9q578/MHwYCHXBHjX/c4Nzu1o5Yi94f+hzQ4cw7U09coHeNp+nqffS5zkiTB4xxGnYaArcZvPXDO0lDMwxC0y0D/T8hTJD/oNg+pq/nj3Gv89sTZ8zn6dpaNqZ0DQnLjbZ2mcd3GuncCIipwebDfD/UT+Vmaa/14iQHpAjvlh8PivEBCZ+e+qbAlAgkIX+HBhiC2wrGO78oajhcNPEctPn/6L3zzcKnbtkj7Ha1R+y5lzVH2rqhQsMU4a+j2bvy3f0EFkwvLURuExfyOv4Q6T1gH9/eKyet0CPT3BbofvNDKnLbGpihvTkBXrzTjXTFsPAyzr0JRVOREROJYbRNEn5WGy2psnNpHVIWacNr8ffg+afw2VzhMxVsjfd7z2itysQEAM9I4EhUggZ2vQ1D0PB7TQ0X3XbNJvPocJoPu/MW9+8Vy4YPh3W56exxjqisb7Kuu529PIf4aZwIiIi0l7sDrC3MuzpiOmcw6IdTGc3ExERkaiicCIiIiJRReFEREREoorCiYiIiEQVhRMRERGJKgonIiIiElUUTkRERCSqKJyIiIhIVFE4ERERkahimOaRJzDoXGJjY0lLC8/yy9XV1SQmaiW/46F9dfy0r46f9tXx0746ftpXxy+c+2rPnj3U19e3+FinDyfh5HK5KCsri3QZnYL21fHTvjp+2lfHT/vq+GlfHb9I7SsN64iIiEhUUTgRERGRqKJw0orZs2dHuoROQ/vq+GlfHT/tq+OnfXX8tK+OX6T2leaciIiISFRRz4mIiIhEFYUTERERiSoKJy0oKChg7NixZGdnM3r0aDZt2hTpkqJCXV0d1113HdnZ2QwbNozLL7+cwsJCACoqKpg4cSIDBw5k8ODBfPzxxxGuNnrMmzcPwzD417/+BWhfHUt9fT133303AwcOZMiQIUyfPh3Q72NL3nrrLXJychg+fDiDBw/mH//4B6DPFsBPfvIT+vXrh2EYrFu3Lnh/a5+j0/Uz1tK+au3vPHTgZ8yUo0yYMMGcN2+eaZqm+corr5ijRo2KbEFRora21nzzzTdNn89nmqZp/vnPfzbHjx9vmqZp3nrrreYvf/lL0zRN8/PPPzczMzPNhoaGCFUaPb799lvz/PPPN8eMGWO++uqrpmlqXx3Lvffea959993Bz1d5eblpmvp9PJLP5zO7d+9url+/3jRN6zMWGxtrVlVV6bNlmuby5cvN0tJSs2/fvuaXX34ZvL+1z9Hp+hlraV+19nfeNDvu75fCyRF2795tJiUlmY2NjaZpWn8IevbsaRYUFES4suizevVqs2/fvqZpmmaXLl2CXyamaZqjR48233vvvQhVFh28Xq956aWXmmvWrDHHjx8fDCfaV0errq42k5KSzMrKymb36/fxaD6fz0xJSTGXL19umqZprl+/3uzdu7dZX1+vz1aI0C/c1j5H+oyZRwW5UKF/502z4/5+aVjnCKWlpWRkZOBwOAAwDAO3201JSUmEK4s+TzzxBNdeey379u2jsbGRXr16BR/r16/fab/P8vLyuOCCCxg5cmTwPu2rlhUVFZGSksLcuXMZNWoU48aN44MPPtDvYwsMw+Cll17i+uuvp2/fvlx44YX84x//4NChQ/psHUNrnyN9xloX+DsPHfv3y9HuW5TTwty5cyksLOSDDz6gtrY20uVEnY0bN7J48eLTcsz/u/B4PGzfvp2zzz6bhx9+mC+//JLLL7+cN998M9KlRR2Px8Nvf/tblixZwkUXXcTq1auZPHlys/kVIu0h9O98R1PPyRH69OlDeXk5Ho8HANM0KSkpwe12R7iy6PHYY4+xZMkS3n77bRISEujRowcOh4Ndu3YF2xQXF5/W+2zFihUUFxczcOBA+vXrx2effcbMmTN5+eWXta9a4Ha7sdlsTJs2DYARI0ZwxhlnsH37dv0+HmHdunXs3LmTiy66CIDRo0fjcrnYsGGDPlvH0Nrfdf3Nb9mRf+eBDv1br3ByhPT0dHJycpg/fz4AixcvxuVykZWVFeHKokNeXh7//Oc/ee+99+jWrVvw/h/84Ac8+eSTAKxevZodO3Ywfvz4CFUZeXfccQfl5eUUFxdTXFzMmDFjeOqpp7jjjju0r1qQmprKpZdeyrvvvgvAt99+y7fffssFF1yg38cjBL5MN2/eDEBhYSFFRUUMGjRIn61jaO3vuv7mH+1Yf+ehA//Wt/ssllPAli1bzDFjxpgDBw40R44caW7YsCHSJUWF0tJSEzD79+9vDhs2zBw2bJh57rnnmqZpmrt27TIvv/xyMysryzz77LPNZcuWRbja6BI6IVb7qmVFRUXmxRdfbA4ePNgcOnSouWjRItM09fvYkoULFwb30+DBg80FCxaYpqnPlmma5syZM83MzEzTbreb6enp5oABA0zTbP1zdLp+xlraV639nTfNjvuMafl6ERERiSoa1hEREZGoonAiIiIiUUXhRERERKKKwomIiIhEFYUTERERiSoKJyIiIhJVtHy9iLSrfv36ERsbS3x8fPC+F154gSFDhkSwKhHpTBRORKTdvfTSSwwfPjzSZYhIJ6VhHRHpEIZh8OCDDzJixAiys7NZsGBB8LF3332XnJwchg4dyvjx4/n666+Dj82bN4/hw4czbNgwRo0aRXFxMR6PhyuuuIJRo0ZxzjnncNNNN3H48GEACgoKuOCCCxg2bBhDhgzhwQcf7PD3KiInRyvEiki7amlY59NPPyUhIYEHH3yQ3/zmN3zzzTeMGjWKtWvXkpCQwFlnncVHH33EkCFDWLBgAb/73e/YtGkTy5cv59Zbb+Xf//43GRkZ1NTUABAfH8/+/fvp0aMHpmly55130rdvXx544AHuueceevXqxX/9138BsH//flJSUiKyL0Tku9Gwjoi0u2MN68yYMQOA/v37c9FFF/Hxxx/TvXt3hgwZEpyTMm3aNO666y527NjBm2++yc0330xGRgZA8OyoPp+Pxx9/nDfffBOPx0NlZSVjx44F4KKLLuK+++6jurqa8ePHc9lll3XAOxaR9qRhHRGJGMMwvtPzFi5cyLJly1i+fDlfffUVP/vZz6irqwNgypQpfPLJJwwaNIi//OUvTJo0qT1LFpEOoHAiIh1m3rx5ABQXF7NixQrGjRvHmDFj+Oqrr9i4cSMAL774IpmZmWRmZnLNNdcwf/58ysvLAaipqaGmpoYDBw6QmppKcnIyhw4d4rnnngu+RkFBAT179uSWW27hkUce4bPPPuvw9ykiJ0fDOiLS7qZOndpszsnjjz8OgNfrZcSIERw+fJg//elP9OvXD4AFCxZwyy234PF46N69O6+88gqGYXDRRRfxy1/+kiuuuALDMIiJiWHRokXccsstvPbaawwaNIi0tDTGjRvH9u3bAVi0aBHz588nJiYGn8/Hk08+2eHvX0ROjibEikiHMAyDAwcO0K1bt0iXIiJRTsM6IiIiElU0rCMiHUKdtCJyvNRzIiIiIlFF4URERESiisKJiIiIRBWFExEREYkqCiciIiISVRROREREJKr8/0HWsbcHMJeUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the validation and train loss\n",
    "plt.figure(figsize=(8, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.plot(np.sqrt(history.history[\"loss\"]))\n",
    "plt.plot(np.sqrt(history.history[\"val_loss\"]))\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epocas\")\n",
    "plt.legend([\"Treino\", \"Validação\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(true_values, pred, labels):\n",
    "    \"\"\"\n",
    "    Function that returns the confusion matrix for a binary classification\n",
    "    \n",
    "    Args:\n",
    "        true_values (list): List of true values\n",
    "        preditos (list): List of predicted values\n",
    "        labels (list): Label value of both classes\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array, in the format:\n",
    "            numpy.array([\n",
    "                [ tp, fp ],\n",
    "                [ fn, tn ]\n",
    "            ])\n",
    "    \"\"\"\n",
    "    if len(labels) > 2:\n",
    "        return None\n",
    "\n",
    "    if len(true_values) != len(pred):\n",
    "        return None\n",
    "    \n",
    "    # Considering the first class positive and second negative\n",
    "    true_class = labels[0]\n",
    "    negative_class = labels[1]\n",
    "\n",
    "    # True positive and true negative\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    \n",
    "    # False positive and false negative\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for (i, v_real) in enumerate(true_values):\n",
    "        v_pred = pred[i]\n",
    "\n",
    "        # se trata de um valor real da classe positiva\n",
    "        if v_real == true_class:\n",
    "            tp += 1 if v_pred == v_real else 0\n",
    "            fp += 1 if v_pred != v_real else 0\n",
    "        else:\n",
    "            tn += 1 if v_pred == v_real else 0\n",
    "            fn += 1 if v_pred != v_real else 0\n",
    "    \n",
    "    return np.array([\n",
    "        # valores da classe positiva\n",
    "        [ tp, fp ],\n",
    "        # valores da classe negativa\n",
    "        [ fn, tn ]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>total</th>\n",
       "      <th>Acc percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>102</td>\n",
       "      <td>97.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tp  fp  fn  tn  total  Acc percent\n",
       "0  31   1   2  68    102    97.058824"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_real = np.array(y_test[:,0],dtype=int).flatten()\n",
    "v_pred = np.array(np.round(pred),dtype=int).flatten()\n",
    "matrix = get_confusion_matrix(v_real, v_pred, [1,0])\n",
    "matrix_df = {'tp': [matrix[0][0]],\n",
    "             'fp': [matrix[0][1]],\n",
    "             'fn': [matrix[1][0]],\n",
    "             'tn': [matrix[1][1]],\n",
    "            'total': [np.sum(matrix)],\n",
    "            'Acc percent': [(matrix[0][0] +matrix[1][1])*100/np.sum(matrix)]}\n",
    "matrix_df = pd.DataFrame(matrix_df)\n",
    "matrix_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding out the best number of neurons on the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.1246 - accuracy: 0.6577 - val_loss: 3.1690 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.6674 - accuracy: 0.7013 - val_loss: 2.8797 - val_accuracy: 0.5825\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.4863 - accuracy: 0.6777 - val_loss: 2.6194 - val_accuracy: 0.5825\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1803 - accuracy: 0.7058 - val_loss: 2.3892 - val_accuracy: 0.5825\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.1012 - accuracy: 0.6658 - val_loss: 2.1835 - val_accuracy: 0.5825\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9122 - accuracy: 0.6646 - val_loss: 1.9997 - val_accuracy: 0.5825\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.7403 - accuracy: 0.6708 - val_loss: 1.8367 - val_accuracy: 0.5825\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6013 - accuracy: 0.6679 - val_loss: 1.6905 - val_accuracy: 0.5825\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4969 - accuracy: 0.6530 - val_loss: 1.5580 - val_accuracy: 0.5825\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4141 - accuracy: 0.6354 - val_loss: 1.4392 - val_accuracy: 0.5825\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3058 - accuracy: 0.6355 - val_loss: 1.3323 - val_accuracy: 0.5825\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1695 - accuracy: 0.6525 - val_loss: 1.2360 - val_accuracy: 0.5825\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.6575 - val_loss: 1.1486 - val_accuracy: 0.5825\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.6363 - val_loss: 1.0686 - val_accuracy: 0.5825\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.6856 - val_loss: 0.9973 - val_accuracy: 0.5825\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8514 - accuracy: 0.6653 - val_loss: 0.9317 - val_accuracy: 0.5825\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8207 - accuracy: 0.6475 - val_loss: 0.8715 - val_accuracy: 0.5825\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.6557 - val_loss: 0.8172 - val_accuracy: 0.5825\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.6360 - val_loss: 0.7665 - val_accuracy: 0.5825\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6795 - val_loss: 0.7216 - val_accuracy: 0.5825\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6379 - val_loss: 0.6798 - val_accuracy: 0.5825\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6496 - val_loss: 0.6417 - val_accuracy: 0.5825\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.6677 - val_loss: 0.6068 - val_accuracy: 0.5825\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.6679 - val_loss: 0.5746 - val_accuracy: 0.5825\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.6316 - val_loss: 0.5447 - val_accuracy: 0.5825\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.6595 - val_loss: 0.5179 - val_accuracy: 0.5825\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.6573 - val_loss: 0.4931 - val_accuracy: 0.5825\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.6623 - val_loss: 0.4698 - val_accuracy: 0.5825\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.6729 - val_loss: 0.4486 - val_accuracy: 0.5825\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.6608 - val_loss: 0.4290 - val_accuracy: 0.5825\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.6598 - val_loss: 0.4110 - val_accuracy: 0.5825\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.6556 - val_loss: 0.3941 - val_accuracy: 0.5825\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.6566 - val_loss: 0.3787 - val_accuracy: 0.5825\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.6366 - val_loss: 0.3642 - val_accuracy: 0.5825\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.6616 - val_loss: 0.3513 - val_accuracy: 0.5825\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.6891 - val_loss: 0.3390 - val_accuracy: 0.5825\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.6593 - val_loss: 0.3274 - val_accuracy: 0.5825\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2671 - accuracy: 0.6569 - val_loss: 0.3168 - val_accuracy: 0.5825\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.6779 - val_loss: 0.3070 - val_accuracy: 0.5825\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.6510 - val_loss: 0.2978 - val_accuracy: 0.5825\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.6352 - val_loss: 0.2892 - val_accuracy: 0.5825\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.6658 - val_loss: 0.2814 - val_accuracy: 0.5825\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.6654 - val_loss: 0.2741 - val_accuracy: 0.5825\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.6592 - val_loss: 0.2671 - val_accuracy: 0.5825\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.6235 - val_loss: 0.2605 - val_accuracy: 0.5825\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.6204 - val_loss: 0.2545 - val_accuracy: 0.5825\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.6690 - val_loss: 0.2491 - val_accuracy: 0.5825\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.6537 - val_loss: 0.2438 - val_accuracy: 0.5825\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.6693 - val_loss: 0.2389 - val_accuracy: 0.5825\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.7065 - val_loss: 0.2343 - val_accuracy: 0.5825\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.6303 - val_loss: 0.2297 - val_accuracy: 0.5825\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.6519 - val_loss: 0.2257 - val_accuracy: 0.5825\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.6606 - val_loss: 0.2218 - val_accuracy: 0.5825\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.6501 - val_loss: 0.2182 - val_accuracy: 0.5825\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.6101 - val_loss: 0.2146 - val_accuracy: 0.5825\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1774 - accuracy: 0.6613 - val_loss: 0.2115 - val_accuracy: 0.5825\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.6376 - val_loss: 0.2084 - val_accuracy: 0.5825\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.6793 - val_loss: 0.2057 - val_accuracy: 0.5825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.6440 - val_loss: 0.2029 - val_accuracy: 0.5825\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.6590 - val_loss: 0.2003 - val_accuracy: 0.5825\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.6427 - val_loss: 0.1978 - val_accuracy: 0.5825\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1571 - accuracy: 0.6746 - val_loss: 0.1955 - val_accuracy: 0.5825\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.6731 - val_loss: 0.1932 - val_accuracy: 0.5825\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.6797 - val_loss: 0.1911 - val_accuracy: 0.5825\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.6728 - val_loss: 0.1891 - val_accuracy: 0.5825\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.6589 - val_loss: 0.1870 - val_accuracy: 0.5825\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.6469 - val_loss: 0.1851 - val_accuracy: 0.5825\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.6663 - val_loss: 0.1833 - val_accuracy: 0.5825\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.6391 - val_loss: 0.1815 - val_accuracy: 0.5825\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.6430 - val_loss: 0.1798 - val_accuracy: 0.5825\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.6577 - val_loss: 0.1782 - val_accuracy: 0.5825\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.6588 - val_loss: 0.1767 - val_accuracy: 0.5825\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.6653 - val_loss: 0.1752 - val_accuracy: 0.5825\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.6393 - val_loss: 0.1736 - val_accuracy: 0.5825\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.6640 - val_loss: 0.1722 - val_accuracy: 0.5825\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.6743 - val_loss: 0.1709 - val_accuracy: 0.5825\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.6645 - val_loss: 0.1694 - val_accuracy: 0.5825\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.6637 - val_loss: 0.1681 - val_accuracy: 0.5825\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.6794 - val_loss: 0.1668 - val_accuracy: 0.5825\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.7005 - val_loss: 0.1656 - val_accuracy: 0.5825\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1381 - accuracy: 0.6792 - val_loss: 0.1642 - val_accuracy: 0.5825\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.6835 - val_loss: 0.1630 - val_accuracy: 0.5825\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.6688 - val_loss: 0.1618 - val_accuracy: 0.5922\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.6521 - val_loss: 0.1605 - val_accuracy: 0.5922\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.6455 - val_loss: 0.1594 - val_accuracy: 0.5922\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.6735 - val_loss: 0.1583 - val_accuracy: 0.5922\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.6577 - val_loss: 0.1571 - val_accuracy: 0.6117\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.6805 - val_loss: 0.1560 - val_accuracy: 0.6117\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.6655 - val_loss: 0.1548 - val_accuracy: 0.6117\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.6767 - val_loss: 0.1537 - val_accuracy: 0.6214\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.7012 - val_loss: 0.1526 - val_accuracy: 0.6214\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.6737 - val_loss: 0.1515 - val_accuracy: 0.6214\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.6718 - val_loss: 0.1503 - val_accuracy: 0.6408\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.6838 - val_loss: 0.1493 - val_accuracy: 0.6408\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.7019 - val_loss: 0.1482 - val_accuracy: 0.6602\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.7072 - val_loss: 0.1471 - val_accuracy: 0.6602\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.7313 - val_loss: 0.1461 - val_accuracy: 0.6699\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.7340 - val_loss: 0.1450 - val_accuracy: 0.6796\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.7194 - val_loss: 0.1439 - val_accuracy: 0.6796\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.7430 - val_loss: 0.1428 - val_accuracy: 0.6893\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.7318 - val_loss: 0.1417 - val_accuracy: 0.6893\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.7371 - val_loss: 0.1406 - val_accuracy: 0.6990\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.7474 - val_loss: 0.1396 - val_accuracy: 0.7184\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.7697 - val_loss: 0.1385 - val_accuracy: 0.7184\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.7890 - val_loss: 0.1374 - val_accuracy: 0.7379\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.7729 - val_loss: 0.1363 - val_accuracy: 0.7573\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.7718 - val_loss: 0.1353 - val_accuracy: 0.7573\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.7872 - val_loss: 0.1342 - val_accuracy: 0.7670\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.7992 - val_loss: 0.1331 - val_accuracy: 0.7864\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8422 - val_loss: 0.1321 - val_accuracy: 0.7864\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.8073 - val_loss: 0.1310 - val_accuracy: 0.7864\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.8267 - val_loss: 0.1299 - val_accuracy: 0.7961\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.7936 - val_loss: 0.1287 - val_accuracy: 0.7961\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.8590 - val_loss: 0.1277 - val_accuracy: 0.7961\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.8456 - val_loss: 0.1266 - val_accuracy: 0.7961\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.8596 - val_loss: 0.1254 - val_accuracy: 0.8058\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.8373 - val_loss: 0.1243 - val_accuracy: 0.8058\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.8570 - val_loss: 0.1232 - val_accuracy: 0.8058\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.8521 - val_loss: 0.1221 - val_accuracy: 0.8155\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.8545 - val_loss: 0.1210 - val_accuracy: 0.8350\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.8614 - val_loss: 0.1199 - val_accuracy: 0.8447\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.8881 - val_loss: 0.1188 - val_accuracy: 0.8544\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.8807 - val_loss: 0.1176 - val_accuracy: 0.8544\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.8760 - val_loss: 0.1165 - val_accuracy: 0.8641\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.8756 - val_loss: 0.1154 - val_accuracy: 0.8738\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.8688 - val_loss: 0.1142 - val_accuracy: 0.8738\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1063 - accuracy: 0.8914 - val_loss: 0.1131 - val_accuracy: 0.8835\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 0.8953 - val_loss: 0.1119 - val_accuracy: 0.8932\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9096 - val_loss: 0.1108 - val_accuracy: 0.8932\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9362 - val_loss: 0.1097 - val_accuracy: 0.8932\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9134 - val_loss: 0.1085 - val_accuracy: 0.8932\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.8931 - val_loss: 0.1073 - val_accuracy: 0.9029\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9086 - val_loss: 0.1062 - val_accuracy: 0.9029\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9254 - val_loss: 0.1051 - val_accuracy: 0.9223\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9046 - val_loss: 0.1039 - val_accuracy: 0.9320\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9109 - val_loss: 0.1028 - val_accuracy: 0.9320\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9017 - val_loss: 0.1016 - val_accuracy: 0.9320\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9266 - val_loss: 0.1005 - val_accuracy: 0.9320\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9131 - val_loss: 0.0993 - val_accuracy: 0.9320\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9212 - val_loss: 0.0982 - val_accuracy: 0.9320\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9293 - val_loss: 0.0971 - val_accuracy: 0.9320\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9232 - val_loss: 0.0960 - val_accuracy: 0.9320\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9364 - val_loss: 0.0948 - val_accuracy: 0.9320\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9362 - val_loss: 0.0937 - val_accuracy: 0.9320\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9428 - val_loss: 0.0926 - val_accuracy: 0.9417\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9438 - val_loss: 0.0915 - val_accuracy: 0.9417\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9396 - val_loss: 0.0903 - val_accuracy: 0.9417\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9414 - val_loss: 0.0893 - val_accuracy: 0.9417\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9473 - val_loss: 0.0881 - val_accuracy: 0.9417\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9369 - val_loss: 0.0871 - val_accuracy: 0.9417\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9390 - val_loss: 0.0860 - val_accuracy: 0.9417\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9503 - val_loss: 0.0848 - val_accuracy: 0.9417\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9404 - val_loss: 0.0838 - val_accuracy: 0.9515\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9283 - val_loss: 0.0827 - val_accuracy: 0.9515\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9639 - val_loss: 0.0816 - val_accuracy: 0.9515\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9460 - val_loss: 0.0806 - val_accuracy: 0.9515\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9485 - val_loss: 0.0795 - val_accuracy: 0.9515\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9603 - val_loss: 0.0785 - val_accuracy: 0.9515\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9525 - val_loss: 0.0775 - val_accuracy: 0.9515\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9409 - val_loss: 0.0764 - val_accuracy: 0.9515\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9461 - val_loss: 0.0755 - val_accuracy: 0.9515\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9388 - val_loss: 0.0744 - val_accuracy: 0.9515\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9380 - val_loss: 0.0734 - val_accuracy: 0.9515\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9418 - val_loss: 0.0724 - val_accuracy: 0.9515\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9482 - val_loss: 0.0714 - val_accuracy: 0.9515\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9580 - val_loss: 0.0705 - val_accuracy: 0.9515\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9467 - val_loss: 0.0695 - val_accuracy: 0.9515\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9426 - val_loss: 0.0686 - val_accuracy: 0.9515\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9561 - val_loss: 0.0676 - val_accuracy: 0.9612\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9549 - val_loss: 0.0667 - val_accuracy: 0.9612\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9598 - val_loss: 0.0658 - val_accuracy: 0.9612\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9641 - val_loss: 0.0649 - val_accuracy: 0.9612\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9654 - val_loss: 0.0640 - val_accuracy: 0.9612\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9702 - val_loss: 0.0631 - val_accuracy: 0.9612\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.9596 - val_loss: 0.0623 - val_accuracy: 0.9612\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9527 - val_loss: 0.0614 - val_accuracy: 0.9612\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9718 - val_loss: 0.0604 - val_accuracy: 0.9612\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9719 - val_loss: 0.0596 - val_accuracy: 0.9612\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9624 - val_loss: 0.0588 - val_accuracy: 0.9612\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9678 - val_loss: 0.0580 - val_accuracy: 0.9612\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9561 - val_loss: 0.0571 - val_accuracy: 0.9612\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9670 - val_loss: 0.0564 - val_accuracy: 0.9709\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9603 - val_loss: 0.0556 - val_accuracy: 0.9709\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9626 - val_loss: 0.0548 - val_accuracy: 0.9709\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9698 - val_loss: 0.0540 - val_accuracy: 0.9709\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9548 - val_loss: 0.0533 - val_accuracy: 0.9709\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9681 - val_loss: 0.0525 - val_accuracy: 0.9709\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9743 - val_loss: 0.0518 - val_accuracy: 0.9709\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9523 - val_loss: 0.0510 - val_accuracy: 0.9709\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9629 - val_loss: 0.0503 - val_accuracy: 0.9709\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9699 - val_loss: 0.0496 - val_accuracy: 0.9709\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9716 - val_loss: 0.0489 - val_accuracy: 0.9709\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9651 - val_loss: 0.0482 - val_accuracy: 0.9709\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9658 - val_loss: 0.0476 - val_accuracy: 0.9709\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9754 - val_loss: 0.0469 - val_accuracy: 0.9709\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9588 - val_loss: 0.0462 - val_accuracy: 0.9709\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9683 - val_loss: 0.0456 - val_accuracy: 0.9709\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9715 - val_loss: 0.0450 - val_accuracy: 0.9709\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9706 - val_loss: 0.0443 - val_accuracy: 0.9709\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9601 - val_loss: 0.0437 - val_accuracy: 0.9709\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.1300 - val_loss: 0.3490 - val_accuracy: 0.1650\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.1638 - val_loss: 0.3156 - val_accuracy: 0.1942\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.2366 - val_loss: 0.2864 - val_accuracy: 0.4854\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.4435 - val_loss: 0.2603 - val_accuracy: 0.6699\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.5987 - val_loss: 0.2373 - val_accuracy: 0.7282\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.7351 - val_loss: 0.2173 - val_accuracy: 0.7767\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.7461 - val_loss: 0.1984 - val_accuracy: 0.7864\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.7772 - val_loss: 0.1810 - val_accuracy: 0.8350\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.7831 - val_loss: 0.1656 - val_accuracy: 0.8738\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.8148 - val_loss: 0.1514 - val_accuracy: 0.8738\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.8133 - val_loss: 0.1392 - val_accuracy: 0.8835\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.8599 - val_loss: 0.1276 - val_accuracy: 0.8835\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.8820 - val_loss: 0.1174 - val_accuracy: 0.8932\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.8931 - val_loss: 0.1078 - val_accuracy: 0.9126\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.8993 - val_loss: 0.0997 - val_accuracy: 0.9223\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9277 - val_loss: 0.0922 - val_accuracy: 0.9320\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9086 - val_loss: 0.0855 - val_accuracy: 0.9515\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9125 - val_loss: 0.0793 - val_accuracy: 0.9515\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9106 - val_loss: 0.0738 - val_accuracy: 0.9515\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9248 - val_loss: 0.0688 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9363 - val_loss: 0.0646 - val_accuracy: 0.9612\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9405 - val_loss: 0.0604 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9570 - val_loss: 0.0570 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9489 - val_loss: 0.0541 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0639 - accuracy: 0.9449 - val_loss: 0.0512 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9573 - val_loss: 0.0486 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9583 - val_loss: 0.0464 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9557 - val_loss: 0.0444 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9511 - val_loss: 0.0427 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9487 - val_loss: 0.0410 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9510 - val_loss: 0.0397 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9524 - val_loss: 0.0385 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9615 - val_loss: 0.0375 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9570 - val_loss: 0.0365 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9602 - val_loss: 0.0356 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9435 - val_loss: 0.0349 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9616 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9665 - val_loss: 0.0338 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9449 - val_loss: 0.0333 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9576 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9589 - val_loss: 0.0325 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9533 - val_loss: 0.0323 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9719 - val_loss: 0.0317 - val_accuracy: 0.9806\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9624 - val_loss: 0.0315 - val_accuracy: 0.9806\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9394 - val_loss: 0.0312 - val_accuracy: 0.9806\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 0.9487 - val_loss: 0.0310 - val_accuracy: 0.9806\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9529 - val_loss: 0.0309 - val_accuracy: 0.9806\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9680 - val_loss: 0.0308 - val_accuracy: 0.9806\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9594 - val_loss: 0.0305 - val_accuracy: 0.9806\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9676 - val_loss: 0.0304 - val_accuracy: 0.9806\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9599 - val_loss: 0.0304 - val_accuracy: 0.9806\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9684 - val_loss: 0.0302 - val_accuracy: 0.9806\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9719 - val_loss: 0.0300 - val_accuracy: 0.9806\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9728 - val_loss: 0.0298 - val_accuracy: 0.9806\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9603 - val_loss: 0.0297 - val_accuracy: 0.9806\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9639 - val_loss: 0.0298 - val_accuracy: 0.9806\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9733 - val_loss: 0.0296 - val_accuracy: 0.9806\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9612 - val_loss: 0.0296 - val_accuracy: 0.9806\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9558 - val_loss: 0.0294 - val_accuracy: 0.9806\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9641 - val_loss: 0.0293 - val_accuracy: 0.9806\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9614 - val_loss: 0.0293 - val_accuracy: 0.9806\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9741 - val_loss: 0.0293 - val_accuracy: 0.9806\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9522 - val_loss: 0.0292 - val_accuracy: 0.9806\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9610 - val_loss: 0.0291 - val_accuracy: 0.9806\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9708 - val_loss: 0.0290 - val_accuracy: 0.9806\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9672 - val_loss: 0.0290 - val_accuracy: 0.9806\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9654 - val_loss: 0.0288 - val_accuracy: 0.9806\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9658 - val_loss: 0.0289 - val_accuracy: 0.9806\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9613 - val_loss: 0.0288 - val_accuracy: 0.9806\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9635 - val_loss: 0.0286 - val_accuracy: 0.9806\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9650 - val_loss: 0.0286 - val_accuracy: 0.9806\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9732 - val_loss: 0.0285 - val_accuracy: 0.9806\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9707 - val_loss: 0.0286 - val_accuracy: 0.9806\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9740 - val_loss: 0.0284 - val_accuracy: 0.9806\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9728 - val_loss: 0.0285 - val_accuracy: 0.9806\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9686 - val_loss: 0.0284 - val_accuracy: 0.9806\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9668 - val_loss: 0.0283 - val_accuracy: 0.9806\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9627 - val_loss: 0.0283 - val_accuracy: 0.9806\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9553 - val_loss: 0.0282 - val_accuracy: 0.9806\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9771 - val_loss: 0.0281 - val_accuracy: 0.9806\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9727 - val_loss: 0.0280 - val_accuracy: 0.9806\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9619 - val_loss: 0.0280 - val_accuracy: 0.9806\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9687 - val_loss: 0.0280 - val_accuracy: 0.9806\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9762 - val_loss: 0.0280 - val_accuracy: 0.9806\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9665 - val_loss: 0.0279 - val_accuracy: 0.9806\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9629 - val_loss: 0.0279 - val_accuracy: 0.9806\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9653 - val_loss: 0.0277 - val_accuracy: 0.9806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9623 - val_loss: 0.0278 - val_accuracy: 0.9806\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9685 - val_loss: 0.0276 - val_accuracy: 0.9806\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9726 - val_loss: 0.0276 - val_accuracy: 0.9806\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9747 - val_loss: 0.0276 - val_accuracy: 0.9806\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9584 - val_loss: 0.0275 - val_accuracy: 0.9806\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9584 - val_loss: 0.0275 - val_accuracy: 0.9806\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9769 - val_loss: 0.0274 - val_accuracy: 0.9806\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9674 - val_loss: 0.0274 - val_accuracy: 0.9806\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9524 - val_loss: 0.0274 - val_accuracy: 0.9806\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9702 - val_loss: 0.0273 - val_accuracy: 0.9806\n",
      "Epoch 00097: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6040 - accuracy: 0.6956 - val_loss: 0.6153 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.6792 - val_loss: 0.4524 - val_accuracy: 0.5825\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.6370 - val_loss: 0.3336 - val_accuracy: 0.5825\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.6589 - val_loss: 0.2526 - val_accuracy: 0.5825\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.6837 - val_loss: 0.1978 - val_accuracy: 0.5825\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.6824 - val_loss: 0.1601 - val_accuracy: 0.6311\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.6840 - val_loss: 0.1332 - val_accuracy: 0.7087\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.7658 - val_loss: 0.1167 - val_accuracy: 0.8350\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.8635 - val_loss: 0.1052 - val_accuracy: 0.9223\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.8731 - val_loss: 0.0956 - val_accuracy: 0.9417\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9181 - val_loss: 0.0891 - val_accuracy: 0.9417\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9176 - val_loss: 0.0830 - val_accuracy: 0.9515\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9394 - val_loss: 0.0776 - val_accuracy: 0.9515\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9280 - val_loss: 0.0730 - val_accuracy: 0.9612\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9424 - val_loss: 0.0689 - val_accuracy: 0.9612\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9424 - val_loss: 0.0653 - val_accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9384 - val_loss: 0.0617 - val_accuracy: 0.9612\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9460 - val_loss: 0.0582 - val_accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9451 - val_loss: 0.0552 - val_accuracy: 0.9612\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9583 - val_loss: 0.0523 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9451 - val_loss: 0.0499 - val_accuracy: 0.9612\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9634 - val_loss: 0.0474 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9590 - val_loss: 0.0451 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9452 - val_loss: 0.0431 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9693 - val_loss: 0.0413 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0513 - accuracy: 0.9569 - val_loss: 0.0397 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9635 - val_loss: 0.0380 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9519 - val_loss: 0.0367 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9509 - val_loss: 0.0356 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9616 - val_loss: 0.0342 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9576 - val_loss: 0.0332 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9613 - val_loss: 0.0322 - val_accuracy: 0.9806\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9578 - val_loss: 0.0313 - val_accuracy: 0.9806\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9636 - val_loss: 0.0306 - val_accuracy: 0.9806\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9631 - val_loss: 0.0301 - val_accuracy: 0.9806\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9767 - val_loss: 0.0292 - val_accuracy: 0.9806\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9638 - val_loss: 0.0287 - val_accuracy: 0.9806\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9661 - val_loss: 0.0282 - val_accuracy: 0.9806\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9693 - val_loss: 0.0279 - val_accuracy: 0.9806\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9513 - val_loss: 0.0274 - val_accuracy: 0.9806\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9793 - val_loss: 0.0271 - val_accuracy: 0.9806\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9657 - val_loss: 0.0267 - val_accuracy: 0.9806\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9764 - val_loss: 0.0263 - val_accuracy: 0.9806\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9718 - val_loss: 0.0261 - val_accuracy: 0.9806\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9731 - val_loss: 0.0259 - val_accuracy: 0.9806\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9620 - val_loss: 0.0258 - val_accuracy: 0.9806\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9631 - val_loss: 0.0254 - val_accuracy: 0.9806\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9682 - val_loss: 0.0254 - val_accuracy: 0.9806\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9656 - val_loss: 0.0251 - val_accuracy: 0.9806\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9635 - val_loss: 0.0250 - val_accuracy: 0.9806\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9744 - val_loss: 0.0250 - val_accuracy: 0.9806\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9783 - val_loss: 0.0248 - val_accuracy: 0.9806\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9696 - val_loss: 0.0247 - val_accuracy: 0.9806\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9778 - val_loss: 0.0247 - val_accuracy: 0.9806\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9652 - val_loss: 0.0246 - val_accuracy: 0.9806\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9750 - val_loss: 0.0245 - val_accuracy: 0.9806\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9728 - val_loss: 0.0244 - val_accuracy: 0.9806\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9750 - val_loss: 0.0244 - val_accuracy: 0.9806\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9658 - val_loss: 0.0243 - val_accuracy: 0.9806\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9744 - val_loss: 0.0242 - val_accuracy: 0.9806\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9839 - val_loss: 0.0242 - val_accuracy: 0.9806\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9686 - val_loss: 0.0242 - val_accuracy: 0.9806\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9597 - val_loss: 0.0241 - val_accuracy: 0.9806\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9678 - val_loss: 0.0240 - val_accuracy: 0.9806\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9731 - val_loss: 0.0240 - val_accuracy: 0.9806\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9764 - val_loss: 0.0240 - val_accuracy: 0.9806\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9799 - val_loss: 0.0240 - val_accuracy: 0.9806\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9766 - val_loss: 0.0239 - val_accuracy: 0.9806\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9706 - val_loss: 0.0237 - val_accuracy: 0.9806\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9666 - val_loss: 0.0238 - val_accuracy: 0.9806\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9634 - val_loss: 0.0239 - val_accuracy: 0.9806\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9828 - val_loss: 0.0238 - val_accuracy: 0.9806\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9694 - val_loss: 0.0236 - val_accuracy: 0.9806\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9782 - val_loss: 0.0236 - val_accuracy: 0.9806\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9620 - val_loss: 0.0238 - val_accuracy: 0.9806\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9762 - val_loss: 0.0236 - val_accuracy: 0.9806\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9737 - val_loss: 0.0237 - val_accuracy: 0.9806\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9631 - val_loss: 0.0236 - val_accuracy: 0.9806\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9717 - val_loss: 0.0235 - val_accuracy: 0.9806\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9748 - val_loss: 0.0236 - val_accuracy: 0.9806\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9757 - val_loss: 0.0235 - val_accuracy: 0.9806\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9801 - val_loss: 0.0234 - val_accuracy: 0.9806\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9657 - val_loss: 0.0235 - val_accuracy: 0.9806\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9807 - val_loss: 0.0233 - val_accuracy: 0.9806\n",
      "Epoch 00084: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9909 - accuracy: 0.6988 - val_loss: 0.9524 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7677 - accuracy: 0.6698 - val_loss: 0.6849 - val_accuracy: 0.5825\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.6883 - val_loss: 0.4862 - val_accuracy: 0.5825\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.6636 - val_loss: 0.3427 - val_accuracy: 0.5825\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.6288 - val_loss: 0.2408 - val_accuracy: 0.5825\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.6603 - val_loss: 0.1727 - val_accuracy: 0.6505\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.7187 - val_loss: 0.1270 - val_accuracy: 0.7379\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.7992 - val_loss: 0.0983 - val_accuracy: 0.8447\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.8614 - val_loss: 0.0792 - val_accuracy: 0.9029\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9180 - val_loss: 0.0668 - val_accuracy: 0.9417\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0657 - accuracy: 0.9319 - val_loss: 0.0589 - val_accuracy: 0.9417\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.9312 - val_loss: 0.0538 - val_accuracy: 0.9515\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9463 - val_loss: 0.0500 - val_accuracy: 0.9709\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9552 - val_loss: 0.0473 - val_accuracy: 0.9709\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9472 - val_loss: 0.0454 - val_accuracy: 0.9709\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9579 - val_loss: 0.0435 - val_accuracy: 0.9709\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9400 - val_loss: 0.0420 - val_accuracy: 0.9709\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9698 - val_loss: 0.0407 - val_accuracy: 0.9709\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9650 - val_loss: 0.0394 - val_accuracy: 0.9709\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9467 - val_loss: 0.0384 - val_accuracy: 0.9709\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9553 - val_loss: 0.0375 - val_accuracy: 0.9709\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9559 - val_loss: 0.0366 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9481 - val_loss: 0.0358 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9538 - val_loss: 0.0351 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9594 - val_loss: 0.0343 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9664 - val_loss: 0.0335 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9689 - val_loss: 0.0330 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9641 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9776 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9424 - val_loss: 0.0316 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9595 - val_loss: 0.0311 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9567 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9685 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9584 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9516 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9639 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9675 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9587 - val_loss: 0.0290 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9664 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9643 - val_loss: 0.0285 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9671 - val_loss: 0.0284 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9522 - val_loss: 0.0282 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9561 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9712 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9484 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9597 - val_loss: 0.0277 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9614 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9602 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9696 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9630 - val_loss: 0.0273 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9624 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9635 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9558 - val_loss: 0.0270 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9641 - val_loss: 0.0270 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9518 - val_loss: 0.0270 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9629 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9563 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9578 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9685 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9705 - val_loss: 0.0266 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9449 - val_loss: 0.0266 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9459 - val_loss: 0.0265 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9569 - val_loss: 0.0265 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9741 - val_loss: 0.0264 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9534 - val_loss: 0.0264 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9615 - val_loss: 0.0264 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9684 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9515 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9578 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9464 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9624 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9689 - val_loss: 0.0260 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9550 - val_loss: 0.0260 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9673 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9593 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9625 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 00076: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.3676 - val_loss: 0.2707 - val_accuracy: 0.4175\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.3293 - val_loss: 0.2055 - val_accuracy: 0.6796\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.7786 - val_loss: 0.1639 - val_accuracy: 0.9029\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9183 - val_loss: 0.1320 - val_accuracy: 0.9029\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9493 - val_loss: 0.1087 - val_accuracy: 0.9126\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9206 - val_loss: 0.0907 - val_accuracy: 0.9223\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9529 - val_loss: 0.0779 - val_accuracy: 0.9223\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9381 - val_loss: 0.0673 - val_accuracy: 0.9320\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9468 - val_loss: 0.0603 - val_accuracy: 0.9417\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9365 - val_loss: 0.0549 - val_accuracy: 0.9612\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9701 - val_loss: 0.0518 - val_accuracy: 0.9515\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9569 - val_loss: 0.0481 - val_accuracy: 0.9612\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9606 - val_loss: 0.0462 - val_accuracy: 0.9612\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9531 - val_loss: 0.0444 - val_accuracy: 0.9612\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9501 - val_loss: 0.0434 - val_accuracy: 0.9612\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9569 - val_loss: 0.0426 - val_accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9583 - val_loss: 0.0415 - val_accuracy: 0.9612\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9483 - val_loss: 0.0409 - val_accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9504 - val_loss: 0.0406 - val_accuracy: 0.9612\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9580 - val_loss: 0.0399 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9409 - val_loss: 0.0392 - val_accuracy: 0.9612\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9545 - val_loss: 0.0392 - val_accuracy: 0.9612\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9550 - val_loss: 0.0389 - val_accuracy: 0.9612\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9631 - val_loss: 0.0382 - val_accuracy: 0.9612\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9544 - val_loss: 0.0376 - val_accuracy: 0.9612\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9625 - val_loss: 0.0377 - val_accuracy: 0.9612\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9569 - val_loss: 0.0371 - val_accuracy: 0.9612\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9649 - val_loss: 0.0369 - val_accuracy: 0.9612\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9543 - val_loss: 0.0367 - val_accuracy: 0.9612\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9513 - val_loss: 0.0363 - val_accuracy: 0.9612\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9543 - val_loss: 0.0361 - val_accuracy: 0.9612\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9547 - val_loss: 0.0356 - val_accuracy: 0.9612\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9549 - val_loss: 0.0355 - val_accuracy: 0.9612\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9579 - val_loss: 0.0351 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9629 - val_loss: 0.0349 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9671 - val_loss: 0.0345 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9634 - val_loss: 0.0346 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - accuracy: 0.9658 - val_loss: 0.0341 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9589 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9543 - val_loss: 0.0338 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9602 - val_loss: 0.0334 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9533 - val_loss: 0.0334 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9649 - val_loss: 0.0331 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9627 - val_loss: 0.0330 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9572 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9540 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9520 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9608 - val_loss: 0.0325 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9500 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9416 - val_loss: 0.0319 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9581 - val_loss: 0.0319 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9716 - val_loss: 0.0315 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9619 - val_loss: 0.0315 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9594 - val_loss: 0.0315 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9598 - val_loss: 0.0310 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9618 - val_loss: 0.0309 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9715 - val_loss: 0.0311 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9598 - val_loss: 0.0309 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9557 - val_loss: 0.0306 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9533 - val_loss: 0.0305 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9590 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9760 - val_loss: 0.0303 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9672 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9647 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9538 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9587 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9669 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9627 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9690 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9677 - val_loss: 0.0294 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9668 - val_loss: 0.0294 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9685 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9611 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9654 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9581 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9691 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9736 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9623 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9651 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9777 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9605 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9656 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9594 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9628 - val_loss: 0.0282 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9840 - val_loss: 0.0280 - val_accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9789 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9682 - val_loss: 0.0280 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - accuracy: 0.9703 - val_loss: 0.0278 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9642 - val_loss: 0.0278 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9764 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9721 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9627 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9683 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9692 - val_loss: 0.0273 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9793 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9675 - val_loss: 0.0273 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9728 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9679 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9699 - val_loss: 0.0270 - val_accuracy: 0.9709\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9647 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9728 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9801 - val_loss: 0.0267 - val_accuracy: 0.9709\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9722 - val_loss: 0.0270 - val_accuracy: 0.9709\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9681 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9713 - val_loss: 0.0267 - val_accuracy: 0.9709\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9724 - val_loss: 0.0266 - val_accuracy: 0.9709\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9673 - val_loss: 0.0266 - val_accuracy: 0.9709\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9735 - val_loss: 0.0265 - val_accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9484 - val_loss: 0.0267 - val_accuracy: 0.9709\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9686 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9688 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9798 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9767 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9809 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9690 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9718 - val_loss: 0.0258 - val_accuracy: 0.9709\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9651 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9678 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9752 - val_loss: 0.0258 - val_accuracy: 0.9709\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9707 - val_loss: 0.0256 - val_accuracy: 0.9709\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9686 - val_loss: 0.0257 - val_accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9700 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9710 - val_loss: 0.0256 - val_accuracy: 0.9709\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9585 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9664 - val_loss: 0.0257 - val_accuracy: 0.9709\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9724 - val_loss: 0.0253 - val_accuracy: 0.9709\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9688 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9714 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9751 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9775 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9594 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9749 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9787 - val_loss: 0.0251 - val_accuracy: 0.9709\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9731 - val_loss: 0.0250 - val_accuracy: 0.9709\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9745 - val_loss: 0.0249 - val_accuracy: 0.9709\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9685 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9611 - val_loss: 0.0251 - val_accuracy: 0.9709\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9720 - val_loss: 0.0249 - val_accuracy: 0.9709\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9736 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9747 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9700 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9715 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9702 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9660 - val_loss: 0.0245 - val_accuracy: 0.9709\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9726 - val_loss: 0.0245 - val_accuracy: 0.9709\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9754 - val_loss: 0.0244 - val_accuracy: 0.9709\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9734 - val_loss: 0.0243 - val_accuracy: 0.9709\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9772 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9786 - val_loss: 0.0244 - val_accuracy: 0.9709\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9726 - val_loss: 0.0242 - val_accuracy: 0.9709\n",
      "Epoch 00150: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.1700 - accuracy: 0.6885 - val_loss: 0.1584 - val_accuracy: 0.7573\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.8217 - val_loss: 0.1322 - val_accuracy: 0.9029\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9239 - val_loss: 0.1180 - val_accuracy: 0.9029\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.8922 - val_loss: 0.1038 - val_accuracy: 0.9223\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9280 - val_loss: 0.0913 - val_accuracy: 0.9223\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9279 - val_loss: 0.0790 - val_accuracy: 0.9223\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9224 - val_loss: 0.0702 - val_accuracy: 0.9320\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9446 - val_loss: 0.0620 - val_accuracy: 0.9417\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9375 - val_loss: 0.0549 - val_accuracy: 0.9515\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9580 - val_loss: 0.0490 - val_accuracy: 0.9515\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - accuracy: 0.9504 - val_loss: 0.0450 - val_accuracy: 0.9612\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9716 - val_loss: 0.0412 - val_accuracy: 0.9612\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9590 - val_loss: 0.0382 - val_accuracy: 0.9612\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9563 - val_loss: 0.0363 - val_accuracy: 0.9709\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9596 - val_loss: 0.0349 - val_accuracy: 0.9709\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9693 - val_loss: 0.0335 - val_accuracy: 0.9709\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9730 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9717 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9733 - val_loss: 0.0313 - val_accuracy: 0.9709\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9707 - val_loss: 0.0314 - val_accuracy: 0.9709\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9681 - val_loss: 0.0311 - val_accuracy: 0.9709\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9698 - val_loss: 0.0307 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9671 - val_loss: 0.0309 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9692 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9636 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9697 - val_loss: 0.0303 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9608 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9593 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9744 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9678 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9561 - val_loss: 0.0299 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9695 - val_loss: 0.0297 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9696 - val_loss: 0.0299 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9667 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9783 - val_loss: 0.0294 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9752 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9656 - val_loss: 0.0294 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9534 - val_loss: 0.0293 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9718 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9660 - val_loss: 0.0290 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9604 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9716 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9674 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9697 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9598 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9648 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9604 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9765 - val_loss: 0.0284 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9749 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9739 - val_loss: 0.0284 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9585 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9615 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9685 - val_loss: 0.0284 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9608 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9688 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9685 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9777 - val_loss: 0.0278 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9631 - val_loss: 0.0277 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9621 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9570 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9683 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9663 - val_loss: 0.0278 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9684 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9687 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9521 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9730 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9776 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9381 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9765 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9736 - val_loss: 0.0272 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9657 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9680 - val_loss: 0.0269 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9636 - val_loss: 0.0264 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9704 - val_loss: 0.0268 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9538 - val_loss: 0.0267 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9633 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9726 - val_loss: 0.0269 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9663 - val_loss: 0.0262 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9735 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9670 - val_loss: 0.0266 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9663 - val_loss: 0.0261 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9745 - val_loss: 0.0263 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9786 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9739 - val_loss: 0.0259 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9665 - val_loss: 0.0261 - val_accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9711 - val_loss: 0.0258 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9678 - val_loss: 0.0260 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9754 - val_loss: 0.0258 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9683 - val_loss: 0.0257 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9628 - val_loss: 0.0258 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9673 - val_loss: 0.0254 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9744 - val_loss: 0.0256 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9690 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9743 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9783 - val_loss: 0.0255 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9567 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9671 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9697 - val_loss: 0.0253 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9826 - val_loss: 0.0250 - val_accuracy: 0.9709\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9643 - val_loss: 0.0254 - val_accuracy: 0.9709\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9765 - val_loss: 0.0249 - val_accuracy: 0.9709\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9699 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9826 - val_loss: 0.0252 - val_accuracy: 0.9709\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9448 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9760 - val_loss: 0.0248 - val_accuracy: 0.9709\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9748 - val_loss: 0.0250 - val_accuracy: 0.9709\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9683 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9667 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9768 - val_loss: 0.0247 - val_accuracy: 0.9709\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9694 - val_loss: 0.0246 - val_accuracy: 0.9709\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9693 - val_loss: 0.0244 - val_accuracy: 0.9709\n",
      "Epoch 00111: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3335 - accuracy: 0.6930 - val_loss: 1.0045 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.7690 - accuracy: 0.6521 - val_loss: 0.5030 - val_accuracy: 0.5825\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.6396 - val_loss: 0.2399 - val_accuracy: 0.6214\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7180 - val_loss: 0.1228 - val_accuracy: 0.7864\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.8512 - val_loss: 0.0789 - val_accuracy: 0.8835\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9074 - val_loss: 0.0635 - val_accuracy: 0.9417\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9267 - val_loss: 0.0580 - val_accuracy: 0.9417\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9503 - val_loss: 0.0550 - val_accuracy: 0.9515\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9660 - val_loss: 0.0527 - val_accuracy: 0.9515\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9601 - val_loss: 0.0508 - val_accuracy: 0.9515\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9513 - val_loss: 0.0492 - val_accuracy: 0.9515\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9630 - val_loss: 0.0476 - val_accuracy: 0.9515\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9347 - val_loss: 0.0459 - val_accuracy: 0.9515\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9507 - val_loss: 0.0452 - val_accuracy: 0.9515\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9570 - val_loss: 0.0440 - val_accuracy: 0.9515\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9479 - val_loss: 0.0430 - val_accuracy: 0.9515\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9626 - val_loss: 0.0421 - val_accuracy: 0.9612\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9434 - val_loss: 0.0415 - val_accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9482 - val_loss: 0.0409 - val_accuracy: 0.9612\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9557 - val_loss: 0.0403 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9589 - val_loss: 0.0400 - val_accuracy: 0.9612\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9570 - val_loss: 0.0394 - val_accuracy: 0.9612\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9617 - val_loss: 0.0392 - val_accuracy: 0.9612\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9612 - val_loss: 0.0390 - val_accuracy: 0.9612\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9612 - val_loss: 0.0386 - val_accuracy: 0.9612\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9462 - val_loss: 0.0382 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9629 - val_loss: 0.0382 - val_accuracy: 0.9612\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9529 - val_loss: 0.0382 - val_accuracy: 0.9612\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9364 - val_loss: 0.0380 - val_accuracy: 0.9612\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9551 - val_loss: 0.0376 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9596 - val_loss: 0.0375 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9626 - val_loss: 0.0374 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9676 - val_loss: 0.0374 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9572 - val_loss: 0.0372 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9591 - val_loss: 0.0370 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9699 - val_loss: 0.0368 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9654 - val_loss: 0.0368 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9627 - val_loss: 0.0368 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9498 - val_loss: 0.0365 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9523 - val_loss: 0.0365 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9621 - val_loss: 0.0366 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9593 - val_loss: 0.0361 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9597 - val_loss: 0.0361 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9534 - val_loss: 0.0361 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9557 - val_loss: 0.0361 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9568 - val_loss: 0.0357 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9670 - val_loss: 0.0357 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9585 - val_loss: 0.0357 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9535 - val_loss: 0.0356 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9528 - val_loss: 0.0354 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9500 - val_loss: 0.0354 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9450 - val_loss: 0.0353 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9629 - val_loss: 0.0352 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9515 - val_loss: 0.0350 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9668 - val_loss: 0.0352 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9659 - val_loss: 0.0348 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9648 - val_loss: 0.0348 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9534 - val_loss: 0.0348 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9379 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9671 - val_loss: 0.0346 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9613 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9551 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9529 - val_loss: 0.0342 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9605 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9655 - val_loss: 0.0342 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9610 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9582 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9628 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9692 - val_loss: 0.0338 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9670 - val_loss: 0.0337 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9335 - val_loss: 0.0336 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9462 - val_loss: 0.0334 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9613 - val_loss: 0.0336 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9588 - val_loss: 0.0334 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9656 - val_loss: 0.0335 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9587 - val_loss: 0.0332 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9583 - val_loss: 0.0332 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9712 - val_loss: 0.0333 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9590 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9544 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9673 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9594 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9557 - val_loss: 0.0329 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9630 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9778 - val_loss: 0.0325 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9681 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9611 - val_loss: 0.0326 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9551 - val_loss: 0.0325 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9662 - val_loss: 0.0325 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9564 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9742 - val_loss: 0.0322 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9544 - val_loss: 0.0323 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9489 - val_loss: 0.0322 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9571 - val_loss: 0.0323 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9638 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9525 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9568 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9585 - val_loss: 0.0319 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9600 - val_loss: 0.0320 - val_accuracy: 0.9709\n",
      "Epoch 00099: early stopping\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5064 - accuracy: 0.6479 - val_loss: 0.3349 - val_accuracy: 0.5825\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.6964 - val_loss: 0.1960 - val_accuracy: 0.6019\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.7518 - val_loss: 0.1560 - val_accuracy: 0.8544\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.8740 - val_loss: 0.1365 - val_accuracy: 0.8835\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.8991 - val_loss: 0.1207 - val_accuracy: 0.8835\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.8665 - val_loss: 0.1045 - val_accuracy: 0.9320\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9023 - val_loss: 0.0912 - val_accuracy: 0.9417\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9330 - val_loss: 0.0797 - val_accuracy: 0.9417\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9433 - val_loss: 0.0709 - val_accuracy: 0.9417\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.9411 - val_loss: 0.0624 - val_accuracy: 0.9515\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9480 - val_loss: 0.0567 - val_accuracy: 0.9515\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9578 - val_loss: 0.0516 - val_accuracy: 0.9515\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9413 - val_loss: 0.0479 - val_accuracy: 0.9612\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9488 - val_loss: 0.0449 - val_accuracy: 0.9612\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9495 - val_loss: 0.0427 - val_accuracy: 0.9612\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9517 - val_loss: 0.0410 - val_accuracy: 0.9612\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9704 - val_loss: 0.0393 - val_accuracy: 0.9612\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9603 - val_loss: 0.0386 - val_accuracy: 0.9612\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9580 - val_loss: 0.0376 - val_accuracy: 0.9709\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9706 - val_loss: 0.0374 - val_accuracy: 0.9612\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9648 - val_loss: 0.0367 - val_accuracy: 0.9709\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9574 - val_loss: 0.0363 - val_accuracy: 0.9709\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9564 - val_loss: 0.0362 - val_accuracy: 0.9709\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9443 - val_loss: 0.0360 - val_accuracy: 0.9709\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9552 - val_loss: 0.0354 - val_accuracy: 0.9709\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9590 - val_loss: 0.0357 - val_accuracy: 0.9709\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9570 - val_loss: 0.0353 - val_accuracy: 0.9709\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9633 - val_loss: 0.0349 - val_accuracy: 0.9709\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9660 - val_loss: 0.0348 - val_accuracy: 0.9709\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9662 - val_loss: 0.0348 - val_accuracy: 0.9709\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9690 - val_loss: 0.0347 - val_accuracy: 0.9709\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9665 - val_loss: 0.0344 - val_accuracy: 0.9709\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9708 - val_loss: 0.0341 - val_accuracy: 0.9709\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9648 - val_loss: 0.0340 - val_accuracy: 0.9709\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9654 - val_loss: 0.0341 - val_accuracy: 0.9709\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9641 - val_loss: 0.0337 - val_accuracy: 0.9709\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9639 - val_loss: 0.0336 - val_accuracy: 0.9709\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9585 - val_loss: 0.0337 - val_accuracy: 0.9709\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9420 - val_loss: 0.0332 - val_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9695 - val_loss: 0.0331 - val_accuracy: 0.9709\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9748 - val_loss: 0.0331 - val_accuracy: 0.9709\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9637 - val_loss: 0.0334 - val_accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9467 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9652 - val_loss: 0.0328 - val_accuracy: 0.9709\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9599 - val_loss: 0.0327 - val_accuracy: 0.9709\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9467 - val_loss: 0.0323 - val_accuracy: 0.9709\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9487 - val_loss: 0.0324 - val_accuracy: 0.9709\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9593 - val_loss: 0.0325 - val_accuracy: 0.9709\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9614 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9744 - val_loss: 0.0321 - val_accuracy: 0.9709\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9626 - val_loss: 0.0318 - val_accuracy: 0.9709\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9593 - val_loss: 0.0318 - val_accuracy: 0.9709\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9598 - val_loss: 0.0317 - val_accuracy: 0.9709\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9691 - val_loss: 0.0319 - val_accuracy: 0.9709\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9612 - val_loss: 0.0314 - val_accuracy: 0.9709\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9651 - val_loss: 0.0317 - val_accuracy: 0.9709\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9609 - val_loss: 0.0314 - val_accuracy: 0.9709\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9452 - val_loss: 0.0312 - val_accuracy: 0.9709\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9708 - val_loss: 0.0316 - val_accuracy: 0.9709\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9619 - val_loss: 0.0310 - val_accuracy: 0.9709\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9525 - val_loss: 0.0312 - val_accuracy: 0.9709\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9526 - val_loss: 0.0309 - val_accuracy: 0.9709\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9669 - val_loss: 0.0308 - val_accuracy: 0.9709\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9622 - val_loss: 0.0312 - val_accuracy: 0.9709\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9630 - val_loss: 0.0307 - val_accuracy: 0.9709\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9747 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9630 - val_loss: 0.0307 - val_accuracy: 0.9709\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9565 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9501 - val_loss: 0.0306 - val_accuracy: 0.9709\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9584 - val_loss: 0.0305 - val_accuracy: 0.9709\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9685 - val_loss: 0.0303 - val_accuracy: 0.9709\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9633 - val_loss: 0.0302 - val_accuracy: 0.9709\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9763 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9628 - val_loss: 0.0304 - val_accuracy: 0.9709\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9697 - val_loss: 0.0302 - val_accuracy: 0.9709\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9630 - val_loss: 0.0299 - val_accuracy: 0.9709\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9589 - val_loss: 0.0300 - val_accuracy: 0.9709\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9666 - val_loss: 0.0299 - val_accuracy: 0.9709\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9658 - val_loss: 0.0301 - val_accuracy: 0.9709\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9709 - val_loss: 0.0297 - val_accuracy: 0.9709\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9642 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9533 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9631 - val_loss: 0.0298 - val_accuracy: 0.9709\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9542 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9560 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9666 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9692 - val_loss: 0.0294 - val_accuracy: 0.9709\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9596 - val_loss: 0.0293 - val_accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9682 - val_loss: 0.0295 - val_accuracy: 0.9709\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9701 - val_loss: 0.0293 - val_accuracy: 0.9709\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9563 - val_loss: 0.0296 - val_accuracy: 0.9709\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9615 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9593 - val_loss: 0.0290 - val_accuracy: 0.9709\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9611 - val_loss: 0.0292 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9640 - val_loss: 0.0289 - val_accuracy: 0.9709\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9675 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9655 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9633 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9726 - val_loss: 0.0289 - val_accuracy: 0.9709\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9605 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9560 - val_loss: 0.0286 - val_accuracy: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9593 - val_loss: 0.0291 - val_accuracy: 0.9709\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9708 - val_loss: 0.0284 - val_accuracy: 0.9709\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9646 - val_loss: 0.0286 - val_accuracy: 0.9709\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9645 - val_loss: 0.0285 - val_accuracy: 0.9709\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9690 - val_loss: 0.0287 - val_accuracy: 0.9709\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9587 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9744 - val_loss: 0.0288 - val_accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9649 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9688 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9625 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9758 - val_loss: 0.0280 - val_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9575 - val_loss: 0.0283 - val_accuracy: 0.9709\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9679 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9697 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9771 - val_loss: 0.0280 - val_accuracy: 0.9709\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9749 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9647 - val_loss: 0.0281 - val_accuracy: 0.9709\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9710 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9689 - val_loss: 0.0280 - val_accuracy: 0.9709\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9560 - val_loss: 0.0276 - val_accuracy: 0.9709\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9599 - val_loss: 0.0277 - val_accuracy: 0.9709\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9704 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9635 - val_loss: 0.0279 - val_accuracy: 0.9709\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9714 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9592 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9557 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9713 - val_loss: 0.0273 - val_accuracy: 0.9709\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9653 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9613 - val_loss: 0.0271 - val_accuracy: 0.9709\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9761 - val_loss: 0.0275 - val_accuracy: 0.9709\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9642 - val_loss: 0.0274 - val_accuracy: 0.9709\n",
      "Epoch 00132: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Testing different number of neurons\n",
    "neurons = [5,10,15,30]\n",
    "repetitions = 2\n",
    "result = list()\n",
    "for neuron in neurons:\n",
    "    result_i = list()\n",
    "    for i in range(0,repetitions):\n",
    "        lr = 0.001  # learning rate\n",
    "        lr_decay = 0.0005# learning rate decay\n",
    "        n_mini_batch = 100  # mini-batch length\n",
    "        activation_fcn = \"sigmoid\"\n",
    "        optimizer = Adam(lr=lr, decay=lr_decay)\n",
    "        input_dim = x.shape[1]\n",
    "        h_n = neuron\n",
    "        model = Sequential()\n",
    "        model.add(Dense(h_n, input_dim=input_dim, activation=activation_fcn))\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        # Train and validate the model\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            y_train[:, 0],\n",
    "            validation_data=(x_val, y_val[:, 0]),\n",
    "            epochs=200,\n",
    "            batch_size=30,\n",
    "            # verbose=0,\n",
    "            callbacks=[\n",
    "                EarlyStopping(\n",
    "                    monitor=\"val_loss\", mode=\"min\", min_delta=0.001, patience=20, verbose=1\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "        pred = model.predict(x_test)\n",
    "        pred = np.array(pred).flatten()\n",
    "\n",
    "        erro = pred - np.array(y_test[:, 0]).flatten()\n",
    "        erro = np.abs(erro)\n",
    "\n",
    "        acerto = 0\n",
    "        for i in erro:\n",
    "            if i < 0.5:\n",
    "                acerto += 1\n",
    "\n",
    "        result_i.append(acerto)\n",
    "    result.append(result_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result).reshape((len(neurons),repetitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>results_1</th>\n",
       "      <th>results_2</th>\n",
       "      <th>mean</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>mean_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>99.5</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>97.087379</td>\n",
       "      <td>96.601942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "      <td>96.116505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neurons  results_1  results_2  mean      acc_1      acc_2   mean_acc\n",
       "0        5         99        100  99.5  96.116505  97.087379  96.601942\n",
       "1       10         99         99  99.0  96.116505  96.116505  96.116505\n",
       "2       15         99         99  99.0  96.116505  96.116505  96.116505\n",
       "3       30         99         99  99.0  96.116505  96.116505  96.116505"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = [np.mean(i) for i in result]\n",
    "acc  = np.array(result) * (100/len(y_val)) \n",
    "mean_acc = np.array(mean) * (100/len(y_val))\n",
    "\n",
    "result_dict = {'neurons': neurons, 'results_1': result[:,0],'results_2':result[:,1], 'mean': mean, 'acc_1' : acc[:,0],'acc_2' : acc[:,1] , 'mean_acc': mean_acc}\n",
    "result_df = pd.DataFrame(data=result_dict)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
