{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset shape:  (699, 11)\nID                         int64\nClump                      int64\nU_Cell_size                int64\nU_Cell_shape               int64\nMarginal_Adhesion          int64\nSE_epitelial_cell_size     int64\nBare_nuclei               object\nbland_chromatin            int64\nNormal_Nucleoli            int64\nMitoses                    int64\nClass                      int64\ndtype: object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        ID  Clump  U_Cell_size  U_Cell_shape  Marginal_Adhesion  \\\n",
       "0  1000025      5            1             1                  1   \n",
       "1  1002945      5            4             4                  5   \n",
       "2  1015425      3            1             1                  1   \n",
       "3  1016277      6            8             8                  1   \n",
       "4  1017023      4            1             1                  3   \n",
       "\n",
       "   SE_epitelial_cell_size Bare_nuclei  bland_chromatin  Normal_Nucleoli  \\\n",
       "0                       2           1                3                1   \n",
       "1                       7          10                3                2   \n",
       "2                       2           2                3                1   \n",
       "3                       3           4                3                7   \n",
       "4                       2           1                3                1   \n",
       "\n",
       "   Mitoses  Class  \n",
       "0        1      2  \n",
       "1        1      2  \n",
       "2        1      2  \n",
       "3        1      2  \n",
       "4        1      2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Clump</th>\n      <th>U_Cell_size</th>\n      <th>U_Cell_shape</th>\n      <th>Marginal_Adhesion</th>\n      <th>SE_epitelial_cell_size</th>\n      <th>Bare_nuclei</th>\n      <th>bland_chromatin</th>\n      <th>Normal_Nucleoli</th>\n      <th>Mitoses</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000025</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002945</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1015425</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1016277</td>\n      <td>6</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1017023</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "data_csv = \"../breast-cancer-wisconsin.csv\"\n",
    "df = pd.read_csv(data_csv, names=['ID','Clump','U_Cell_size','U_Cell_shape','Marginal_Adhesion','SE_epitelial_cell_size','Bare_nuclei','bland_chromatin','Normal_Nucleoli','Mitoses','Class'])\n",
    "print('Dataset shape: ', df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "#  Attribute                     Domain\n",
    "-- -----------------------------------------\n",
    "1. Sample code number            id number\n",
    "2. Clump Thickness               1 - 10\n",
    "3. Uniformity of Cell Size       1 - 10\n",
    "4. Uniformity of Cell Shape      1 - 10\n",
    "5. Marginal Adhesion             1 - 10\n",
    "6. Single Epithelial Cell Size   1 - 10\n",
    "7. Bare Nuclei                   1 - 10\n",
    "8. Bland Chromatin               1 - 10\n",
    "9. Normal Nucleoli               1 - 10\n",
    "10. Mitoses                       1 - 10\n",
    "11. Class:                        (0 for benign, 1 for malignant)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16\n0\nNew dataset shape:  (683, 10)\n"
     ]
    }
   ],
   "source": [
    "# Change bare nuclei values to numeric only and check the numbers of NAN\n",
    "df['Bare_nuclei'] = pd.to_numeric(df['Bare_nuclei'], errors='coerce', downcast='integer')\n",
    "print(df['Bare_nuclei'].isnull().values.sum())\n",
    "\n",
    "# Drop the lines with null values\n",
    "df = df.dropna()\n",
    "print(df['Bare_nuclei'].isnull().values.sum())\n",
    "\n",
    "# Removing ID column since it won't be considered to the training\n",
    "df.pop('ID')\n",
    "\n",
    "# So, the dataset removing null values and ID column has the size:\n",
    "print('New dataset shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Clump \nMin Value:   1 \nMax Value:  10 \n\n\nU_Cell_size \nMin Value:   1 \nMax Value:  10 \n\n\nU_Cell_shape \nMin Value:   1 \nMax Value:  10 \n\n\nMarginal_Adhesion \nMin Value:   1 \nMax Value:  10 \n\n\nSE_epitelial_cell_size \nMin Value:   1 \nMax Value:  10 \n\n\nBare_nuclei \nMin Value:   1.0 \nMax Value:  10.0 \n\n\nbland_chromatin \nMin Value:   1 \nMax Value:  10 \n\n\nNormal_Nucleoli \nMin Value:   1 \nMax Value:  10 \n\n\nMitoses \nMin Value:   1 \nMax Value:  10 \n\n\nClass \nMin Value:   2 \nMax Value:  4 \n\n\n"
     ]
    }
   ],
   "source": [
    "#Values distribution\n",
    "for name, values in df.iteritems():\n",
    "    print (name, '\\nMin Value:  ', np.min(values), '\\nMax Value: ', np.max(values), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class\nMin Value:   0 \nMax Value:  1 \n\n\n"
     ]
    }
   ],
   "source": [
    "# Changing Class label from 2 or 4 to 0 or 1\n",
    "df.loc[:, 'Class'] = np.where(df['Class']==2, 0, 1)\n",
    "print ('Class\\nMin Value:  ', np.min(df['Class']), '\\nMax Value: ', np.max(df['Class']), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total     = 683 -> 100%\nBenign    = 444 -> 65.00732064421669%\nMalignant = 239 -> 34.99267935578331%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total     = {len(df)} -> 100%\")\n",
    "print(f\"Benign    = {len(df[df.Class == 0])} -> {len(df[df.Class == 0])/len(df) *100}%\")\n",
    "print(f\"Malignant = {len(df[df.Class == 1])} -> {len(df[df.Class == 1])/len(df) *100}%\")"
   ]
  },
  {
   "source": [
    "# (Todo Issue #4) Here we should add the correlation plots correspondents to the paper figures 13 and 14"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation code to plot figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(683, 9)\n",
      "(683,)\n",
      "<ipython-input-8-436484144921>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dataset = df.to_numpy(dtype=np.int) # Converting from Pandas dataframe to Numpy\n"
     ]
    }
   ],
   "source": [
    "# Separate entries from outputs\n",
    "dataset = df.to_numpy(dtype=np.int) # Converting from Pandas dataframe to Numpy\n",
    "entries = dataset[:, 0:9]\n",
    "outputs = dataset[:, 9]\n",
    "print(entries.shape)\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset shape:\nEntries:  (450, 9) \nOutput:  (450,) \n\n\nTest dataset shape:\nEntries:  (233, 9) \nOutput:  (233,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset between train and test\n",
    "seed = 10 # Set seed to get invariant results\n",
    "test_size = 0.34\n",
    "x_train, x_test, y_train, y_test = train_test_split(entries, outputs, test_size=test_size, random_state=seed)\n",
    "print('Train dataset shape:\\nEntries: ', x_train.shape, '\\nOutput: ', y_train.shape, '\\n\\n')\n",
    "print('Test dataset shape:\\nEntries: ', x_test.shape, '\\nOutput: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10-fold validation set for training\n",
    "K = 10\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "source": [
    "# Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree classifier\n",
    "dt = tree.DecisionTreeClassifier(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation Accuracy =  0.9555555555555556 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9777777777777777 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9333333333333333 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9555555555555556 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.8888888888888888 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9555555555555556 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.8666666666666667 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.8888888888888888 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9777777777777777 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n",
      "Validation Accuracy =  0.9555555555555556 , Train dataset shape:  (405, 9) Validation dataset shape:  (45,)\n"
     ]
    }
   ],
   "source": [
    "# Training the decision tree using cross-validation\n",
    "for train_indexes, valid_indexes in kf.split(x_train):\n",
    "    dt.fit(x_train[train_indexes], y_train[train_indexes])\n",
    "    y_valid_pred = dt.predict(x_train[valid_indexes])\n",
    "    print(\"Validation Accuracy = \", accuracy_score(y_train[valid_indexes], y_valid_pred), \n",
    "            \", Train dataset shape: \", x_train[train_indexes].shape, \n",
    "            \"Validation dataset shape: \", y_train[valid_indexes].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Accuracy =  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Testing the decision tree\n",
    "y_test = dt.predict(x_test)\n",
    "print(\"Test Accuracy = \", accuracy_score(y_train[valid_indexes], y_valid_pred))"
   ]
  },
  {
   "source": [
    "# (Todo Issue #5) Calculates the confusion matrix and define the variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True Negative:  441\nFalse Positive:  3\nFalse Negative:  13\nTrue Positive: 226\n"
     ]
    }
   ],
   "source": [
    "# Code calculating decision matrix, defining variables from issue #5 and show a confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(outputs, dt.predict(entries)).ravel()\n",
    "print(\"True Negative: \", tn)\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"False Negative: \", fn)\n",
    "print(\"True Positive:\", tp)"
   ]
  },
  {
   "source": [
    "# (Todo Issue #6) Calculates the performance metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.9765739385065886\nPrecision:  0.9868995633187773\nSpecificity:  0.9932432432432432\nTP Rate:  0.9456066945606695\nFP Rate:  0.006756756756756757\nNPV:  0.9713656387665198\nRate of Misclassification:  0.02342606149341142\nF1 Score:  0.4829059829059829\n"
     ]
    }
   ],
   "source": [
    "# Code to calculate performance metrics as described on issue #6\n",
    "\n",
    "# 4.1 accuracy\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# 4.2 precision\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "# 4.3 specificity\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity: \", specificity)\n",
    "\n",
    "# 4.4 TP rate\n",
    "tp_rate = tp / (tp + fn)\n",
    "print(\"TP Rate: \", tp_rate)\n",
    "\n",
    "# 4.5 FP rate\n",
    "fp_rate = fp / (fp + tn)\n",
    "print(\"FP Rate: \", fp_rate)\n",
    "\n",
    "# 4.6 NPV\n",
    "npv = tn / (tn + fn)\n",
    "print(\"NPV: \", npv)\n",
    "\n",
    "# 4.7 Rate of Misclassification\n",
    "misclassification_rate = (fp + fn) / (tp + tn + fp + fn)\n",
    "print(\"Rate of Misclassification: \", misclassification_rate)\n",
    "\n",
    "# 4.8 F1 Score\n",
    "f1_score = (precision * tp_rate) / (precision + tp_rate)\n",
    "print(\"F1 Score: \",  f1_score)"
   ]
  },
  {
   "source": [
    "# (Todo Issue #7) Create ROC Curves"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create ROC curve"
   ]
  },
  {
   "source": [
    "# Paper negative points  (Let's make a list to use after)\n",
    "- Does not mention the null values present at `Bare_nuclei` atribute\n",
    "- Does not treat the proportion of benign and malign samples at training and test dataset\n",
    "- We assume that `ID` column is not used to the training, but paper seems to consider it\n",
    "- Normalization of entry values could improve the performance for some methods as NN\n",
    "- Use a repeated K-fold cross validation could improve the performance\n",
    "- Use grid-search to tune decision tree parameters could be implemented\n",
    "- Does not specify any of the Decision tree parameters used (or they just use the default implementation without set any parameters)\n",
    "- Calculates the decision matrix over the entire dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}